{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":116062,"databundleVersionId":14875579,"isSourceIdPinned":false,"sourceType":"competition"},{"sourceId":13665986,"sourceType":"datasetVersion","datasetId":8688768},{"sourceId":13680623,"sourceType":"datasetVersion","datasetId":8699749}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# ============================================================================\n# Section 1: C·∫§U H√åNH & IMPORT\n# ============================================================================\nimport numpy as np\nimport pandas as pd\nimport os\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nimport gc\nimport warnings\n!pip install goatools\n\n# T·∫Øt c√°c c·∫£nh b√°o kh√¥ng c·∫ßn thi·∫øt\nwarnings.filterwarnings('ignore')\n\n# --- C·∫§U H√åNH ƒê∆Ø·ªúNG D·∫™N (Ch·ªâ d√πng T5) ---\n# H√£y ƒë·∫£m b·∫£o ƒë∆∞·ªùng d·∫´n n√†y ƒë√∫ng v·ªõi dataset T5 b·∫°n ƒë√£ add\nEMBED_DIR = '/kaggle/input/cafa-6-t5-embeddings' \nTRAIN_TERMS_PATH = '/kaggle/input/cafa-6-protein-function-prediction/Train/train_terms.tsv'\nOBO_PATH = '/kaggle/input/cafa-6-protein-function-prediction/Train/go-basic.obo'\n\n# --- HYPERPARAMETERS (T·ªêI ∆ØU H√ìA) ---\nBATCH_SIZE = 512       # Batch l·ªõn gi√∫p train nhanh v√† ·ªïn ƒë·ªãnh gradient\nEPOCHS = 25           # TƒÉng epoch v√¨ d√πng Cosine Scheduler\nLEARNING_RATE = 1e-3   # T·ªëc ƒë·ªô h·ªçc kh·ªüi ƒëi·ªÉm\nNUM_LABELS = 1500      # S·ªë l∆∞·ª£ng nh√£n GO ph·ªï bi·∫øn nh·∫•t\nSEEDS = [42, 2024, 123, 777, 888] # Ensemble 5 m√¥ h√¨nh ƒë·ªÉ k·∫øt qu·∫£ v·ªØng ch·∫Øc nh·∫•t\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"üîß Device: {device}\")\nprint(\"üöÄ Strategy: T5 Embeddings Only + MLP Multi-label\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-13T15:38:34.804153Z","iopub.execute_input":"2025-12-13T15:38:34.804413Z","iopub.status.idle":"2025-12-13T15:39:14.120179Z","shell.execute_reply.started":"2025-12-13T15:38:34.804388Z","shell.execute_reply":"2025-12-13T15:39:14.119326Z"}},"outputs":[{"name":"stdout","text":"Collecting goatools\n  Downloading goatools-1.5.2-py3-none-any.whl.metadata (14 kB)\nCollecting docopt-ng (from goatools)\n  Downloading docopt_ng-0.9.0-py3-none-any.whl.metadata (13 kB)\nCollecting ftpretty (from goatools)\n  Downloading ftpretty-0.4.0-py2.py3-none-any.whl.metadata (6.6 kB)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from goatools) (1.26.4)\nRequirement already satisfied: openpyxl in /usr/local/lib/python3.11/dist-packages (from goatools) (3.1.5)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from goatools) (2.2.3)\nRequirement already satisfied: pydot in /usr/local/lib/python3.11/dist-packages (from goatools) (3.0.4)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from goatools) (2.32.5)\nRequirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from goatools) (14.2.0)\nRequirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from goatools) (1.15.3)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from goatools) (75.2.0)\nRequirement already satisfied: statsmodels in /usr/local/lib/python3.11/dist-packages (from goatools) (0.14.5)\nCollecting xlsxwriter (from goatools)\n  Downloading xlsxwriter-3.2.9-py3-none-any.whl.metadata (2.7 kB)\nRequirement already satisfied: python-dateutil in /usr/local/lib/python3.11/dist-packages (from ftpretty->goatools) (2.9.0.post0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->goatools) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->goatools) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->goatools) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->goatools) (2025.3.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->goatools) (2022.3.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->goatools) (2.4.1)\nRequirement already satisfied: et-xmlfile in /usr/local/lib/python3.11/dist-packages (from openpyxl->goatools) (2.0.0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->goatools) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->goatools) (2025.2)\nRequirement already satisfied: pyparsing>=3.0.9 in /usr/local/lib/python3.11/dist-packages (from pydot->goatools) (3.0.9)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->goatools) (3.4.4)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->goatools) (3.11)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->goatools) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->goatools) (2025.10.5)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->goatools) (4.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->goatools) (2.19.2)\nRequirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.11/dist-packages (from statsmodels->goatools) (1.0.1)\nRequirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.11/dist-packages (from statsmodels->goatools) (25.0)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->goatools) (0.1.2)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil->ftpretty->goatools) (1.17.0)\nRequirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->goatools) (2025.3.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->goatools) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->goatools) (2022.3.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->goatools) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->goatools) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->goatools) (2024.2.0)\nDownloading goatools-1.5.2-py3-none-any.whl (15.8 MB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m15.8/15.8 MB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading docopt_ng-0.9.0-py3-none-any.whl (16 kB)\nDownloading ftpretty-0.4.0-py2.py3-none-any.whl (8.2 kB)\nDownloading xlsxwriter-3.2.9-py3-none-any.whl (175 kB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m175.3/175.3 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: xlsxwriter, docopt-ng, ftpretty, goatools\nSuccessfully installed docopt-ng-0.9.0 ftpretty-0.4.0 goatools-1.5.2 xlsxwriter-3.2.9\nüîß Device: cuda\nüöÄ Strategy: T5 Embeddings Only + MLP Multi-label\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# ============================================================================\n# Section 2: LOAD D·ªÆ LI·ªÜU & CHU·∫®N H√ìA (STANDARD SCALER)\n# ============================================================================\nprint(\"\\n\" + \"=\"*60)\nprint(\"üìÇ B∆Ø·ªöC 1: LOAD D·ªÆ LI·ªÜU T5 & CHU·∫®N H√ìA\")\nprint(\"=\"*60)\n\n# H√†m l√†m s·∫°ch ID ƒë·ªÉ kh·ªõp gi·ªØa c√°c file\ndef clean_id(pid):\n    if isinstance(pid, bytes): pid = pid.decode('utf-8')\n    pid = str(pid).strip()\n    if '|' in pid: \n        parts = pid.split('|')\n        return parts[1] if len(parts) >= 2 else pid\n    return pid\nclean_func = np.vectorize(clean_id)\n\n# 1. Load T5 Embeddings (Train)\nprint(\"1Ô∏è‚É£ Loading T5 Train Embeddings...\")\ntry:\n    X_raw = np.load(os.path.join(EMBED_DIR, 'train_embeds.npy'))\n    ids = clean_func(np.load(os.path.join(EMBED_DIR, 'train_ids.npy')))\n    print(f\"   ‚úì Loaded Shape: {X_raw.shape}\")\nexcept Exception as e:\n    print(f\"‚ùå Error loading T5: {e}\"); exit()\n\n# 2. Load Labels\nprint(\"2Ô∏è‚É£ Loading Labels...\")\ndf_terms = pd.read_csv(TRAIN_TERMS_PATH, sep='\\t')\nif 'EntryID' not in df_terms.columns:\n    df_terms = pd.read_csv(TRAIN_TERMS_PATH, sep='\\t', header=None, names=['EntryID', 'term', 'aspect'])\ndf_terms['EntryID'] = df_terms['EntryID'].apply(clean_id)\n\n# 3. Align Data (T√¨m ID chung)\nprint(\"3Ô∏è‚É£ Aligning Data...\")\ncommon_ids = sorted(list(set(ids) & set(df_terms['EntryID'])))\nprint(f\"   ‚úì S·ªë l∆∞·ª£ng protein d√πng ƒë·ªÉ train: {len(common_ids)}\")\n\nif len(common_ids) == 0: raise ValueError(\"‚ùå Kh√¥ng t√¨m th·∫•y ID chung!\")\n\n# Map ID -> Index\nid_map = {pid: i for i, pid in enumerate(ids)}\nfinal_map = {pid: i for i, pid in enumerate(common_ids)}\n\n# T·∫°o ma tr·∫≠n X, y\nINPUT_DIM = X_raw.shape[1]\nX_all = np.zeros((len(common_ids), INPUT_DIM), dtype=np.float32)\ny_all = np.zeros((len(common_ids), NUM_LABELS), dtype=np.float32)\n\nprint(\"   -> Building Feature Matrix X...\")\nfor i, pid in enumerate(common_ids):\n    X_all[i] = X_raw[id_map[pid]]\n\nprint(\"   -> Building Label Matrix y (Multi-label)...\")\ntop_terms = df_terms['term'].value_counts().head(NUM_LABELS).index.tolist()\nterm2idx = {t: i for i, t in enumerate(top_terms)}\nidx2term = {i: t for i, t in enumerate(top_terms)}\n\nrelevant = df_terms[df_terms['EntryID'].isin(common_ids) & df_terms['term'].isin(top_terms)]\nfor row in relevant.itertuples(index=False):\n    pid = getattr(row, 'EntryID', row[0])\n    term = getattr(row, 'term', row[1])\n    if pid in final_map and term in term2idx:\n        y_all[final_map[pid], term2idx[term]] = 1.0\n\n# 4. CHU·∫®N H√ìA D·ªÆ LI·ªÜU (QUAN TR·ªåNG)\nprint(\"4Ô∏è‚É£ Applying StandardScaler...\")\nscaler = StandardScaler()\nX_all = scaler.fit_transform(X_all) # ƒê∆∞a v·ªÅ Mean=0, Std=1\nprint(\"   ‚úì Done! D·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c chu·∫©n h√≥a.\")\n\n# D·ªçn d·∫πp RAM\ndel X_raw, ids, df_terms, relevant\ngc.collect()\n\nprint(f\"‚úÖ DATA READY: X={X_all.shape}, y={y_all.shape}\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-13T15:39:14.121218Z","iopub.execute_input":"2025-12-13T15:39:14.121841Z","iopub.status.idle":"2025-12-13T15:39:23.340137Z","shell.execute_reply.started":"2025-12-13T15:39:14.121816Z","shell.execute_reply":"2025-12-13T15:39:23.339536Z"}},"outputs":[{"name":"stdout","text":"\n============================================================\nüìÇ B∆Ø·ªöC 1: LOAD D·ªÆ LI·ªÜU T5 & CHU·∫®N H√ìA\n============================================================\n1Ô∏è‚É£ Loading T5 Train Embeddings...\n   ‚úì Loaded Shape: (82404, 1024)\n2Ô∏è‚É£ Loading Labels...\n3Ô∏è‚É£ Aligning Data...\n   ‚úì S·ªë l∆∞·ª£ng protein d√πng ƒë·ªÉ train: 82404\n   -> Building Feature Matrix X...\n   -> Building Label Matrix y (Multi-label)...\n4Ô∏è‚É£ Applying StandardScaler...\n   ‚úì Done! D·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c chu·∫©n h√≥a.\n‚úÖ DATA READY: X=(82404, 1024), y=(82404, 1500)\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# ============================================================================\n# Section 3: MODEL (RESIDUAL MLP) & DATASET (REVERTED TO STANDARD)\n# ============================================================================\n\nclass TensorDataset(Dataset):\n    def __init__(self, X, y=None):\n        self.X = torch.tensor(X, dtype=torch.float32)\n        self.y = torch.tensor(y, dtype=torch.float32) if y is not None else None\n    def __len__(self): return len(self.X)\n    def __getitem__(self, idx):\n        if self.y is not None: return self.X[idx], self.y[idx]\n        return self.X[idx]\n\nclass ResidualBlock(nn.Module):\n    def __init__(self, dim, dropout=0.4): \n        super().__init__()\n        self.net = nn.Sequential(\n            nn.Linear(dim, dim),\n            nn.BatchNorm1d(dim),\n            nn.ReLU(),\n            nn.Dropout(dropout)\n        )\n    def forward(self, x): return x + self.net(x)\n\nclass ResMLP(nn.Module):\n    def __init__(self, inp_dim, out_dim):\n        super().__init__()\n        self.entry = nn.Sequential(\n            nn.Linear(inp_dim, 1024),\n            nn.BatchNorm1d(1024),\n            nn.ReLU(),\n            nn.Dropout(0.35)\n        )\n        self.blocks = nn.Sequential(\n            ResidualBlock(1024),\n            ResidualBlock(1024)\n        )\n        self.head = nn.Linear(1024, out_dim)\n    \n    def forward(self, x):\n        x = self.entry(x)\n        x = self.blocks(x)\n        return self.head(x)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-13T15:39:23.341797Z","iopub.execute_input":"2025-12-13T15:39:23.342066Z","iopub.status.idle":"2025-12-13T15:39:23.349458Z","shell.execute_reply.started":"2025-12-13T15:39:23.342046Z","shell.execute_reply":"2025-12-13T15:39:23.348839Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# ============================================================================\n# Section 4: TRAINING FUNCTION (REVERTED TO BCE)\n# ============================================================================\n\ndef train_single_seed(seed, X_tr, y_tr, X_va, y_va, save_path):\n    print(f\"\\nüé≤ Training Seed: {seed}\")\n    torch.manual_seed(seed)\n    np.random.seed(seed)\n    \n    train_loader = DataLoader(TensorDataset(X_tr, y_tr), batch_size=BATCH_SIZE, shuffle=True)\n    val_loader = DataLoader(TensorDataset(X_va, y_va), batch_size=BATCH_SIZE, shuffle=False)\n    \n    model = ResMLP(INPUT_DIM, NUM_LABELS).to(device)\n    optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=1e-4)\n    \n    # --- QUAY V·ªÄ STANDARD BCE ---\n    # ƒê√¢y l√† h√†m loss ·ªïn ƒë·ªãnh nh·∫•t cho baseline 0.348\n    criterion = nn.BCEWithLogitsLoss()\n    \n    # CosineAnnealing gi√∫p learning rate gi·∫£m m∆∞·ª£t m√†\n    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS, eta_min=1e-6)\n    \n    best_loss = float('inf')\n    \n    for ep in range(EPOCHS):\n        model.train()\n        t_loss = 0\n        for fx, fy in train_loader:\n            fx, fy = fx.to(device), fy.to(device)\n            optimizer.zero_grad()\n            out = model(fx)\n            loss = criterion(out, fy) # BCE d√πng Logits tr·ª±c ti·∫øp, kh√¥ng qua Sigmoid\n            loss.backward()\n            optimizer.step()\n            t_loss += loss.item()\n            \n        model.eval()\n        v_loss = 0\n        with torch.no_grad():\n            for fx, fy in val_loader:\n                # Validation c≈©ng d√πng BCEWithLogitsLoss\n                v_loss += criterion(model(fx.to(device)), fy.to(device)).item()\n        \n        avg_v = v_loss/len(val_loader)\n        \n        if avg_v < best_loss:\n            best_loss = avg_v\n            torch.save(model.state_dict(), save_path)\n            \n        scheduler.step()\n        \n        \n        lr_curr = optimizer.param_groups[0]['lr']\n        print(f\"   Ep {ep+1}/{EPOCHS}: Train={t_loss/len(train_loader):.4f} | Val={avg_v:.4f} | LR={lr_curr:.6f}\")\n            \n    return best_loss","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-13T15:39:23.350238Z","iopub.execute_input":"2025-12-13T15:39:23.350551Z","iopub.status.idle":"2025-12-13T15:39:23.805738Z","shell.execute_reply.started":"2025-12-13T15:39:23.350525Z","shell.execute_reply":"2025-12-13T15:39:23.805002Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# ============================================================================\n# Section 5: CH·∫†Y TRAINING (ENSEMBLE 5 SEEDS)\n# ============================================================================\nprint(\"\\n\" + \"=\"*60)\nprint(\"üöÄ B∆Ø·ªöC 2: TRAIN ENSEMBLE MODELS\")\nprint(\"=\"*60)\n\nos.makedirs('models_t5_final', exist_ok=True)\nmodel_paths = []\n\nfor seed in SEEDS:\n    X_tr, X_va, y_tr, y_va = train_test_split(X_all, y_all, test_size=0.1, random_state=seed)\n    path = f'models_t5_final/model_{seed}.pth'\n    train_single_seed(seed, X_tr, y_tr, X_va, y_va, path)\n    model_paths.append(path)\n    \n    del X_tr, X_va, y_tr, y_va\n    gc.collect()\n    torch.cuda.empty_cache()\n    ","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-13T15:39:23.806561Z","iopub.execute_input":"2025-12-13T15:39:23.806770Z","iopub.status.idle":"2025-12-13T15:42:29.099941Z","shell.execute_reply.started":"2025-12-13T15:39:23.806753Z","shell.execute_reply":"2025-12-13T15:42:29.099368Z"}},"outputs":[{"name":"stdout","text":"\n============================================================\nüöÄ B∆Ø·ªöC 2: TRAIN ENSEMBLE MODELS\n============================================================\n\nüé≤ Training Seed: 42\n   Ep 1/25: Train=0.0251 | Val=0.0134 | LR=0.000996\n   Ep 2/25: Train=0.0129 | Val=0.0122 | LR=0.000984\n   Ep 3/25: Train=0.0120 | Val=0.0117 | LR=0.000965\n   Ep 4/25: Train=0.0115 | Val=0.0114 | LR=0.000938\n   Ep 5/25: Train=0.0112 | Val=0.0112 | LR=0.000905\n   Ep 6/25: Train=0.0109 | Val=0.0112 | LR=0.000865\n   Ep 7/25: Train=0.0107 | Val=0.0111 | LR=0.000819\n   Ep 8/25: Train=0.0106 | Val=0.0110 | LR=0.000768\n   Ep 9/25: Train=0.0104 | Val=0.0109 | LR=0.000713\n   Ep 10/25: Train=0.0102 | Val=0.0109 | LR=0.000655\n   Ep 11/25: Train=0.0101 | Val=0.0109 | LR=0.000594\n   Ep 12/25: Train=0.0099 | Val=0.0108 | LR=0.000532\n   Ep 13/25: Train=0.0098 | Val=0.0108 | LR=0.000469\n   Ep 14/25: Train=0.0097 | Val=0.0108 | LR=0.000407\n   Ep 15/25: Train=0.0095 | Val=0.0107 | LR=0.000346\n   Ep 16/25: Train=0.0094 | Val=0.0107 | LR=0.000288\n   Ep 17/25: Train=0.0093 | Val=0.0107 | LR=0.000233\n   Ep 18/25: Train=0.0092 | Val=0.0107 | LR=0.000182\n   Ep 19/25: Train=0.0091 | Val=0.0107 | LR=0.000136\n   Ep 20/25: Train=0.0090 | Val=0.0107 | LR=0.000096\n   Ep 21/25: Train=0.0089 | Val=0.0107 | LR=0.000063\n   Ep 22/25: Train=0.0089 | Val=0.0107 | LR=0.000036\n   Ep 23/25: Train=0.0088 | Val=0.0107 | LR=0.000017\n   Ep 24/25: Train=0.0088 | Val=0.0107 | LR=0.000005\n   Ep 25/25: Train=0.0088 | Val=0.0107 | LR=0.000001\n\nüé≤ Training Seed: 2024\n   Ep 1/25: Train=0.0250 | Val=0.0136 | LR=0.000996\n   Ep 2/25: Train=0.0129 | Val=0.0123 | LR=0.000984\n   Ep 3/25: Train=0.0120 | Val=0.0117 | LR=0.000965\n   Ep 4/25: Train=0.0115 | Val=0.0115 | LR=0.000938\n   Ep 5/25: Train=0.0112 | Val=0.0113 | LR=0.000905\n   Ep 6/25: Train=0.0109 | Val=0.0112 | LR=0.000865\n   Ep 7/25: Train=0.0107 | Val=0.0111 | LR=0.000819\n   Ep 8/25: Train=0.0106 | Val=0.0111 | LR=0.000768\n   Ep 9/25: Train=0.0104 | Val=0.0110 | LR=0.000713\n   Ep 10/25: Train=0.0102 | Val=0.0110 | LR=0.000655\n   Ep 11/25: Train=0.0101 | Val=0.0109 | LR=0.000594\n   Ep 12/25: Train=0.0099 | Val=0.0109 | LR=0.000532\n   Ep 13/25: Train=0.0098 | Val=0.0109 | LR=0.000469\n   Ep 14/25: Train=0.0097 | Val=0.0109 | LR=0.000407\n   Ep 15/25: Train=0.0095 | Val=0.0108 | LR=0.000346\n   Ep 16/25: Train=0.0094 | Val=0.0108 | LR=0.000288\n   Ep 17/25: Train=0.0093 | Val=0.0108 | LR=0.000233\n   Ep 18/25: Train=0.0092 | Val=0.0108 | LR=0.000182\n   Ep 19/25: Train=0.0091 | Val=0.0108 | LR=0.000136\n   Ep 20/25: Train=0.0090 | Val=0.0108 | LR=0.000096\n   Ep 21/25: Train=0.0089 | Val=0.0108 | LR=0.000063\n   Ep 22/25: Train=0.0089 | Val=0.0107 | LR=0.000036\n   Ep 23/25: Train=0.0088 | Val=0.0107 | LR=0.000017\n   Ep 24/25: Train=0.0088 | Val=0.0107 | LR=0.000005\n   Ep 25/25: Train=0.0088 | Val=0.0107 | LR=0.000001\n\nüé≤ Training Seed: 123\n   Ep 1/25: Train=0.0254 | Val=0.0130 | LR=0.000996\n   Ep 2/25: Train=0.0129 | Val=0.0119 | LR=0.000984\n   Ep 3/25: Train=0.0120 | Val=0.0114 | LR=0.000965\n   Ep 4/25: Train=0.0115 | Val=0.0111 | LR=0.000938\n   Ep 5/25: Train=0.0112 | Val=0.0110 | LR=0.000905\n   Ep 6/25: Train=0.0110 | Val=0.0109 | LR=0.000865\n   Ep 7/25: Train=0.0108 | Val=0.0108 | LR=0.000819\n   Ep 8/25: Train=0.0106 | Val=0.0107 | LR=0.000768\n   Ep 9/25: Train=0.0104 | Val=0.0107 | LR=0.000713\n   Ep 10/25: Train=0.0103 | Val=0.0107 | LR=0.000655\n   Ep 11/25: Train=0.0101 | Val=0.0106 | LR=0.000594\n   Ep 12/25: Train=0.0100 | Val=0.0106 | LR=0.000532\n   Ep 13/25: Train=0.0098 | Val=0.0106 | LR=0.000469\n   Ep 14/25: Train=0.0097 | Val=0.0105 | LR=0.000407\n   Ep 15/25: Train=0.0096 | Val=0.0105 | LR=0.000346\n   Ep 16/25: Train=0.0094 | Val=0.0105 | LR=0.000288\n   Ep 17/25: Train=0.0093 | Val=0.0105 | LR=0.000233\n   Ep 18/25: Train=0.0092 | Val=0.0105 | LR=0.000182\n   Ep 19/25: Train=0.0091 | Val=0.0105 | LR=0.000136\n   Ep 20/25: Train=0.0090 | Val=0.0104 | LR=0.000096\n   Ep 21/25: Train=0.0090 | Val=0.0104 | LR=0.000063\n   Ep 22/25: Train=0.0089 | Val=0.0104 | LR=0.000036\n   Ep 23/25: Train=0.0089 | Val=0.0104 | LR=0.000017\n   Ep 24/25: Train=0.0088 | Val=0.0104 | LR=0.000005\n   Ep 25/25: Train=0.0088 | Val=0.0104 | LR=0.000001\n\nüé≤ Training Seed: 777\n   Ep 1/25: Train=0.0251 | Val=0.0133 | LR=0.000996\n   Ep 2/25: Train=0.0129 | Val=0.0121 | LR=0.000984\n   Ep 3/25: Train=0.0120 | Val=0.0115 | LR=0.000965\n   Ep 4/25: Train=0.0115 | Val=0.0112 | LR=0.000938\n   Ep 5/25: Train=0.0112 | Val=0.0111 | LR=0.000905\n   Ep 6/25: Train=0.0110 | Val=0.0109 | LR=0.000865\n   Ep 7/25: Train=0.0108 | Val=0.0109 | LR=0.000819\n   Ep 8/25: Train=0.0106 | Val=0.0108 | LR=0.000768\n   Ep 9/25: Train=0.0104 | Val=0.0107 | LR=0.000713\n   Ep 10/25: Train=0.0102 | Val=0.0107 | LR=0.000655\n   Ep 11/25: Train=0.0101 | Val=0.0107 | LR=0.000594\n   Ep 12/25: Train=0.0100 | Val=0.0107 | LR=0.000532\n   Ep 13/25: Train=0.0098 | Val=0.0106 | LR=0.000469\n   Ep 14/25: Train=0.0097 | Val=0.0106 | LR=0.000407\n   Ep 15/25: Train=0.0095 | Val=0.0106 | LR=0.000346\n   Ep 16/25: Train=0.0094 | Val=0.0106 | LR=0.000288\n   Ep 17/25: Train=0.0093 | Val=0.0105 | LR=0.000233\n   Ep 18/25: Train=0.0092 | Val=0.0105 | LR=0.000182\n   Ep 19/25: Train=0.0091 | Val=0.0105 | LR=0.000136\n   Ep 20/25: Train=0.0090 | Val=0.0105 | LR=0.000096\n   Ep 21/25: Train=0.0090 | Val=0.0105 | LR=0.000063\n   Ep 22/25: Train=0.0089 | Val=0.0105 | LR=0.000036\n   Ep 23/25: Train=0.0088 | Val=0.0105 | LR=0.000017\n   Ep 24/25: Train=0.0088 | Val=0.0105 | LR=0.000005\n   Ep 25/25: Train=0.0088 | Val=0.0105 | LR=0.000001\n\nüé≤ Training Seed: 888\n   Ep 1/25: Train=0.0249 | Val=0.0134 | LR=0.000996\n   Ep 2/25: Train=0.0128 | Val=0.0122 | LR=0.000984\n   Ep 3/25: Train=0.0120 | Val=0.0116 | LR=0.000965\n   Ep 4/25: Train=0.0115 | Val=0.0113 | LR=0.000938\n   Ep 5/25: Train=0.0112 | Val=0.0112 | LR=0.000905\n   Ep 6/25: Train=0.0109 | Val=0.0111 | LR=0.000865\n   Ep 7/25: Train=0.0107 | Val=0.0110 | LR=0.000819\n   Ep 8/25: Train=0.0105 | Val=0.0109 | LR=0.000768\n   Ep 9/25: Train=0.0104 | Val=0.0108 | LR=0.000713\n   Ep 10/25: Train=0.0102 | Val=0.0108 | LR=0.000655\n   Ep 11/25: Train=0.0101 | Val=0.0108 | LR=0.000594\n   Ep 12/25: Train=0.0099 | Val=0.0107 | LR=0.000532\n   Ep 13/25: Train=0.0098 | Val=0.0107 | LR=0.000469\n   Ep 14/25: Train=0.0097 | Val=0.0107 | LR=0.000407\n   Ep 15/25: Train=0.0095 | Val=0.0106 | LR=0.000346\n   Ep 16/25: Train=0.0094 | Val=0.0106 | LR=0.000288\n   Ep 17/25: Train=0.0093 | Val=0.0106 | LR=0.000233\n   Ep 18/25: Train=0.0092 | Val=0.0106 | LR=0.000182\n   Ep 19/25: Train=0.0091 | Val=0.0105 | LR=0.000136\n   Ep 20/25: Train=0.0090 | Val=0.0106 | LR=0.000096\n   Ep 21/25: Train=0.0089 | Val=0.0105 | LR=0.000063\n   Ep 22/25: Train=0.0089 | Val=0.0105 | LR=0.000036\n   Ep 23/25: Train=0.0088 | Val=0.0105 | LR=0.000017\n   Ep 24/25: Train=0.0088 | Val=0.0105 | LR=0.000005\n   Ep 25/25: Train=0.0088 | Val=0.0105 | LR=0.000001\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# ============================================================================\n# Section 6: D·ª∞ ƒêO√ÅN & H·∫¨U X·ª¨ L√ù (T√çCH H·ª¢P GOA & PROPAGATION)\n# ============================================================================\nimport pandas as pd\nfrom tqdm import tqdm\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"üîÆ B∆Ø·ªöC 3: D·ª∞ ƒêO√ÅN, X·ª¨ L√ù GOA & PROPAGATION\")\nprint(\"=\"*60)\n\n# --- C·∫§U H√åNH ƒê∆Ø·ªúNG D·∫™N M·ªöI ---\n# File GOA b·∫°n ƒë√£ upload\nGOA_PATH = '/kaggle/input/protein-go-annotations/goa_uniprot_all.csv'\nTEMP_FILE = 'submission_raw.tsv'\nFINAL_OUTPUT = 'submission.tsv'\n\n# ---------------------------------------------------------\n# 1. CHU·∫®N B·ªä D·ªÆ LI·ªÜU TEST\n# ---------------------------------------------------------\nprint(\"1Ô∏è‚É£ Loading & Normalizing Test Data...\")\n\ntry:\n    test_emb = np.load(os.path.join(EMBED_DIR, 'test_embeds.npy'))\n    test_ids = clean_func(np.load(os.path.join(EMBED_DIR, 'test_ids.npy')))\n    test_X = scaler.transform(test_emb) # D√πng scaler c·ªßa t·∫≠p train\n    print(f\"   ‚úì Test Shape: {test_X.shape}\")\nexcept Exception as e:\n    print(f\"‚ùå Error loading test data: {e}\"); exit()\n\n# ---------------------------------------------------------\n# 2. D·ª∞ ƒêO√ÅN (ENSEMBLE)\n# ---------------------------------------------------------\nprint(\"2Ô∏è‚É£ Predicting with Ensemble Models...\")\nmodels = [ResMLP(INPUT_DIM, NUM_LABELS).to(device) for _ in model_paths]\nfor i, m in enumerate(models):\n    m.load_state_dict(torch.load(model_paths[i]))\n    m.eval()\n\nloader = DataLoader(TensorDataset(test_X), batch_size=BATCH_SIZE*2, shuffle=False)\n\n# Ghi file th√¥ ƒë·ªÉ ti·∫øt ki·ªám RAM\nwith open(TEMP_FILE, 'w') as f:\n    start_idx = 0\n    with torch.no_grad():\n        for fx in tqdm(loader, desc=\"Inference\"):\n            fx = fx.to(device)\n            bs = fx.size(0)\n            \n            # T√≠nh trung b√¨nh c·ªông x√°c su·∫•t\n            avg_prob = torch.zeros((bs, NUM_LABELS)).to(device)\n            for m in models:\n                avg_prob += torch.sigmoid(m(fx))\n            avg_prob /= len(models)\n            avg_prob = avg_prob.cpu().numpy()\n            \n            # Ghi ra file\n            for k in range(bs):\n                pid = test_ids[start_idx + k]\n                probs = avg_prob[k]\n                # L·∫•y Top 80 ƒë·ªÉ d∆∞ d·∫£ cho b∆∞·ªõc filter\n                top_k = np.argsort(probs)[::-1][:80]\n                \n                for idx in top_k:\n                    sc = probs[idx]\n                    if sc > 0.001: \n                        f.write(f\"{pid}\\t{idx2term[idx]}\\t{sc:.4f}\\n\")\n            start_idx += bs\n\nprint(f\"   ‚úì Raw predictions saved to {TEMP_FILE}\")\ndel test_X, models, loader\ngc.collect()\n\n# ---------------------------------------------------------\n# 3. H·∫¨U X·ª¨ L√ù: GOA KNOWLEDGE & PROPAGATION\n# ---------------------------------------------------------\nprint(\"3Ô∏è‚É£ Applying Advanced Post-Processing...\")\n\n# --- H√†m h·ªó tr·ª£ ---\ndef get_descendants(term, children_map, cache):\n    if term in cache: return cache[term]\n    res = set()\n    if term in children_map:\n        for child in children_map[term]:\n            res.add(child)\n            res.update(get_descendants(child, children_map, cache))\n    cache[term] = res\n    return res\n\ntry:\n    from goatools.obo_parser import GODag\n    if os.path.exists(OBO_PATH):\n        # A. X√¢y d·ª±ng c√¢y OBO\n        print(\"   -> Building GO Hierarchy...\")\n        godag = GODag(OBO_PATH)\n        go_children = {tid: [c.id for c in term.children] for tid, term in godag.items()}\n        \n        # B. Load GOA ƒë·ªÉ l·∫•y Negative & Ground Truth\n        print(f\"   -> Loading External Knowledge from {GOA_PATH}...\")\n        neg_keys = set()\n        pos_df = None\n        \n        if os.path.exists(GOA_PATH):\n            goa_df = pd.read_csv(GOA_PATH)\n            # Chu·∫©n h√≥a t√™n c·ªôt\n            if 'DB_Object_ID' in goa_df.columns: goa_df.rename(columns={'DB_Object_ID':'protein_id'}, inplace=True)\n            if 'GO_ID' in goa_df.columns: goa_df.rename(columns={'GO_ID':'go_term'}, inplace=True)\n            if 'Qualifier' in goa_df.columns: goa_df.rename(columns={'Qualifier':'qualifier'}, inplace=True)\n            \n            # 1. Negative Logic\n            if 'qualifier' in goa_df.columns:\n                neg = goa_df[goa_df['qualifier'].str.contains('NOT', na=False)]\n                if not neg.empty:\n                    desc_cache = {}\n                    print(\"      Proagating Negative Constraints...\")\n                    for pid, grp in neg.groupby('protein_id'):\n                        terms = grp['go_term'].tolist()\n                        all_neg = set(terms)\n                        for t in terms:\n                            all_neg |= get_descendants(t, go_children, desc_cache)\n                        for t in all_neg:\n                            neg_keys.add(f\"{pid}_{t}\")\n                            \n            # 2. Positive Logic (Ground Truth)\n            pos_df = goa_df[~goa_df['qualifier'].str.contains('NOT', na=False)][['protein_id', 'go_term']].copy()\n            pos_df['Score'] = 1.0\n            pos_df.rename(columns={'protein_id':'ProteinID', 'go_term':'Term'}, inplace=True)\n            # L·ªçc m√¢u thu·∫´n\n            pos_df['key'] = pos_df['ProteinID'].astype(str) + '_' + pos_df['Term'].astype(str)\n            pos_df = pos_df[~pos_df['key'].isin(neg_keys)].drop(columns=['key']).drop_duplicates()\n        \n        # C. X·ª≠ l√Ω File D·ª± ƒêo√°n\n        print(\"   -> Processing Predictions...\")\n        # ƒê·ªçc file raw\n        df = pd.read_csv(TEMP_FILE, sep='\\t', names=['ProteinID', 'Term', 'Score'], dtype={'ProteinID': str})\n        \n        # 1. Negative Filtering: X√≥a d√≤ng vi ph·∫°m\n        if neg_keys:\n            df['key'] = df['ProteinID'].astype(str) + '_' + df['Term'].astype(str)\n            init_len = len(df)\n            df = df[~df['key'].isin(neg_keys)].drop(columns=['key'])\n            print(f\"      Removed {init_len - len(df)} negative predictions.\")\n            \n        # 2. Ground Truth Injection: Th√™m nh√£n ƒë√∫ng\n        if pos_df is not None and not pos_df.empty:\n            test_prots = set(df['ProteinID'].unique())\n            relevant_gt = pos_df[pos_df['ProteinID'].isin(test_prots)]\n            df = pd.concat([df, relevant_gt], ignore_index=True)\n            # L·∫•y max score n·∫øu tr√πng\n            df = df.groupby(['ProteinID', 'Term'], as_index=False)['Score'].max()\n            print(f\"      Injected Ground Truth data.\")\n\n        # D. Propagation (Lan truy·ªÅn ƒëi·ªÉm s·ªë l√™n cha)\n        # Logic: ƒêi·ªÉm c·ªßa cha = max(ƒêi·ªÉm cha d·ª± ƒëo√°n, ƒêi·ªÉm c√°c con)\n        print(\"   -> Running Hierarchy Propagation...\")\n        final_rows = []\n        \n        # H√†m propagate t·ªëi ∆∞u h∆°n\n        for pid, grp in tqdm(df.groupby('ProteinID'), desc=\"Propagating\"):\n            scores = dict(zip(grp['Term'], grp['Score']))\n            # Ch·ªâ lan truy·ªÅn nh·ªØng term c√≥ trong OBO\n            terms_to_check = [t for t in scores.keys() if t in godag]\n            \n            for term in terms_to_check:\n                current_score = scores[term]\n                # Lan truy·ªÅn l√™n t·∫•t c·∫£ cha (t·ªï ti√™n)\n                parents = godag[term].get_all_parents()\n                for p in parents:\n                    scores[p] = max(scores.get(p, 0), current_score)\n            \n            # L·ªçc threshold cu·ªëi c√πng\n            final_rows.extend([[pid, t, s] for t, s in scores.items() if s >= 0.01])\n\n        # E. L∆∞u File Cu·ªëi\n        res_df = pd.DataFrame(final_rows, columns=['ProteinID', 'Term', 'Score'])\n        res_df['Score'] = res_df['Score'].apply(lambda x: f\"{x:.3f}\")\n        \n        # S·∫Øp x·∫øp nh·∫π ƒë·ªÉ ƒë·∫πp file (kh√¥ng b·∫Øt bu·ªôc nh∆∞ng t·ªët)\n        res_df.sort_values(by=['ProteinID', 'Score'], ascending=[True, False], inplace=True)\n        \n        res_df.to_csv(FINAL_OUTPUT, sep='\\t', index=False, header=False)\n        print(f\"‚úÖ DONE! Final Submission Saved: {FINAL_OUTPUT}\")\n\n    else:\n        print(\"‚ö†Ô∏è OBO file missing. Renaming raw file.\")\n        os.rename(TEMP_FILE, FINAL_OUTPUT)\n\nexcept Exception as e:\n    print(f\"‚ùå Critical Error in Post-processing: {e}\")\n    # Fallback: N·∫øu l·ªói th√¨ n·ªôp file raw\n    if os.path.exists(TEMP_FILE):\n        print(\"   -> Fallback to raw submission.\")\n        if os.path.exists(FINAL_OUTPUT): os.remove(FINAL_OUTPUT)\n        os.rename(TEMP_FILE, FINAL_OUTPUT)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-13T15:42:29.100882Z","iopub.execute_input":"2025-12-13T15:42:29.101223Z","iopub.status.idle":"2025-12-13T15:48:33.548391Z","shell.execute_reply.started":"2025-12-13T15:42:29.101203Z","shell.execute_reply":"2025-12-13T15:48:33.547555Z"}},"outputs":[{"name":"stdout","text":"\n============================================================\nüîÆ B∆Ø·ªöC 3: D·ª∞ ƒêO√ÅN, X·ª¨ L√ù GOA & PROPAGATION\n============================================================\n1Ô∏è‚É£ Loading & Normalizing Test Data...\n   ‚úì Test Shape: (224309, 1024)\n2Ô∏è‚É£ Predicting with Ensemble Models...\n","output_type":"stream"},{"name":"stderr","text":"Inference: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 220/220 [01:04<00:00,  3.44it/s]\n","output_type":"stream"},{"name":"stdout","text":"   ‚úì Raw predictions saved to submission_raw.tsv\n3Ô∏è‚É£ Applying Advanced Post-Processing...\n   -> Building GO Hierarchy...\n/kaggle/input/cafa-6-protein-function-prediction/Train/go-basic.obo: fmt(1.2) rel(2025-06-01) 43,448 Terms\n   -> Loading External Knowledge from /kaggle/input/protein-go-annotations/goa_uniprot_all.csv...\n      Proagating Negative Constraints...\n   -> Processing Predictions...\n      Removed 3145 negative predictions.\n      Injected Ground Truth data.\n   -> Running Hierarchy Propagation...\n","output_type":"stream"},{"name":"stderr","text":"Propagating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 224309/224309 [03:09<00:00, 1185.48it/s]\n","output_type":"stream"},{"name":"stdout","text":"‚úÖ DONE! Final Submission Saved: submission.tsv\n","output_type":"stream"}],"execution_count":6}]}