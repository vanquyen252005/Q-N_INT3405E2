{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T05:06:15.902831Z",
     "iopub.status.busy": "2025-12-14T05:06:15.902482Z",
     "iopub.status.idle": "2025-12-14T05:06:19.885486Z",
     "shell.execute_reply": "2025-12-14T05:06:19.884804Z",
     "shell.execute_reply.started": "2025-12-14T05:06:15.902806Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đang sử dụng thiết bị: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "import gc\n",
    "import os\n",
    "\n",
    "# --- CẤU HÌNH ---\n",
    "# Hãy sửa đường dẫn cho đúng với máy của bạn\n",
    "TRAIN_SEQ_PATH = '/kaggle/input/btl-ml/cafa-6-protein-function-prediction/Train/train_sequences.fasta' \n",
    "TRAIN_TERMS_PATH = '/kaggle/input/btl-ml/cafa-6-protein-function-prediction/Train/train_terms.tsv'\n",
    "TEST_SEQ_PATH = '/kaggle/input/btl-ml/cafa-6-protein-function-prediction/Test/testsuperset.fasta'\n",
    "OBO_PATH = '/kaggle/input/btl-ml/cafa-6-protein-function-prediction/Train/go-basic.obo'\n",
    "\n",
    "BATCH_SIZE = 32      # Tăng lên 64 cho ổn định\n",
    "EPOCHS = 20         # Tăng thời gian học\n",
    "LEARNING_RATE = 0.001\n",
    "NUM_LABELS = 1500    # Tăng số lượng nhãn để model học rộng hơn\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Đang sử dụng thiết bị: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T05:06:19.886552Z",
     "iopub.status.busy": "2025-12-14T05:06:19.886186Z",
     "iopub.status.idle": "2025-12-14T05:06:19.894880Z",
     "shell.execute_reply": "2025-12-14T05:06:19.894215Z",
     "shell.execute_reply.started": "2025-12-14T05:06:19.886525Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# --- 1. HÀM XỬ LÝ DỮ LIỆU ---\n",
    "\n",
    "def load_fasta(path):\n",
    "    \"\"\"Đọc file FASTA và lấy ID chính xác\"\"\"\n",
    "    sequences = {}\n",
    "    current_id = None\n",
    "    current_seq = []\n",
    "    \n",
    "    with open(path, 'r') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if line.startswith('>'):\n",
    "                if current_id:\n",
    "                    sequences[current_id] = ''.join(current_seq)\n",
    "                \n",
    "                header = line[1:]\n",
    "                # Xử lý header dạng 'sp|ID|Name' hoặc '>ID'\n",
    "                if '|' in header:\n",
    "                    parts = header.split('|')\n",
    "                    if len(parts) > 1:\n",
    "                        current_id = parts[1]\n",
    "                    else:\n",
    "                        current_id = header.split()[0]\n",
    "                else:\n",
    "                    current_id = header.split()[0]\n",
    "                    \n",
    "                current_seq = []\n",
    "            else:\n",
    "                current_seq.append(line)\n",
    "        if current_id:\n",
    "            sequences[current_id] = ''.join(current_seq)\n",
    "    return sequences\n",
    "\n",
    "def get_dipeptide_composition(sequence):\n",
    "    \"\"\"\n",
    "    Tạo vector đặc trưng 400 chiều từ tần suất cặp axit amin.\n",
    "    Input: Chuỗi protein. Output: Vector (400,)\n",
    "    \"\"\"\n",
    "    aa_list = 'ACDEFGHIKLMNPQRSTVWY'\n",
    "    aa_map = {aa: i for i, aa in enumerate(aa_list)}\n",
    "    \n",
    "    dipeptide_counts = np.zeros((20, 20), dtype=np.float32)\n",
    "    length = len(sequence)\n",
    "    \n",
    "    if length < 2: \n",
    "        return dipeptide_counts.flatten()\n",
    "    \n",
    "    for i in range(length - 1):\n",
    "        a1 = sequence[i]\n",
    "        a2 = sequence[i+1]\n",
    "        if a1 in aa_map and a2 in aa_map:\n",
    "            dipeptide_counts[aa_map[a1], aa_map[a2]] += 1\n",
    "            \n",
    "    return dipeptide_counts.flatten() / (length - 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T05:06:19.896787Z",
     "iopub.status.busy": "2025-12-14T05:06:19.896562Z",
     "iopub.status.idle": "2025-12-14T05:06:22.431871Z",
     "shell.execute_reply": "2025-12-14T05:06:22.431069Z",
     "shell.execute_reply.started": "2025-12-14T05:06:19.896750Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Đang đọc dữ liệu Train...\n",
      "Số lượng protein hợp lệ: 76297\n"
     ]
    }
   ],
   "source": [
    "# --- 2. CHUẨN BỊ DATASET ---\n",
    "\n",
    "print(\"1. Đang đọc dữ liệu Train...\")\n",
    "train_seqs = load_fasta(TRAIN_SEQ_PATH)\n",
    "train_terms = pd.read_csv(TRAIN_TERMS_PATH, sep='\\t')\n",
    "\n",
    "# Lọc top N nhãn phổ biến nhất\n",
    "top_terms = train_terms['term'].value_counts().head(NUM_LABELS).index.tolist()\n",
    "term_to_idx = {term: i for i, term in enumerate(top_terms)}\n",
    "idx_to_term = {i: term for term, i in term_to_idx.items()} # Dùng để map ngược lại khi dự đoán\n",
    "\n",
    "# Lọc dữ liệu train chỉ giữ lại các dòng thuộc top terms\n",
    "train_terms_filtered = train_terms[train_terms['term'].isin(top_terms)]\n",
    "protein_to_labels = train_terms_filtered.groupby('EntryID')['term'].apply(list).to_dict()\n",
    "\n",
    "# Lấy danh sách protein hợp lệ (có cả sequence và label)\n",
    "valid_ids = [pid for pid in train_seqs.keys() if pid in protein_to_labels]\n",
    "print(f\"Số lượng protein hợp lệ: {len(valid_ids)}\")\n",
    "\n",
    "class CAFA6Dataset(Dataset):\n",
    "    def __init__(self, protein_ids, seq_dict, label_dict, term_map, num_classes):\n",
    "        self.protein_ids = protein_ids\n",
    "        self.seq_dict = seq_dict\n",
    "        self.label_dict = label_dict\n",
    "        self.term_map = term_map\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.protein_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        pid = self.protein_ids[idx]\n",
    "        seq = self.seq_dict[pid]\n",
    "        \n",
    "        # Tạo feature 400 chiều\n",
    "        features = get_dipeptide_composition(seq)\n",
    "        \n",
    "        # Tạo label one-hot\n",
    "        labels = np.zeros(self.num_classes, dtype=np.float32)\n",
    "        if pid in self.label_dict:\n",
    "            for term in self.label_dict[pid]:\n",
    "                if term in self.term_map:\n",
    "                    labels[self.term_map[term]] = 1.0\n",
    "        \n",
    "        return torch.tensor(features, dtype=torch.float32), torch.tensor(labels, dtype=torch.float32)\n",
    "\n",
    "# Chia tập train/val\n",
    "train_ids, val_ids = train_test_split(valid_ids, test_size=0.1, random_state=42)\n",
    "\n",
    "train_dataset = CAFA6Dataset(train_ids, train_seqs, protein_to_labels, term_to_idx, NUM_LABELS)\n",
    "val_dataset = CAFA6Dataset(val_ids, train_seqs, protein_to_labels, term_to_idx, NUM_LABELS)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T05:06:22.433022Z",
     "iopub.status.busy": "2025-12-14T05:06:22.432716Z",
     "iopub.status.idle": "2025-12-14T05:06:22.442710Z",
     "shell.execute_reply": "2025-12-14T05:06:22.442003Z",
     "shell.execute_reply.started": "2025-12-14T05:06:22.432976Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# --- 3. MÔ HÌNH RES-MLP ---\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, dim, dropout_rate=0.4):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.layer = nn.Sequential(\n",
    "            nn.Linear(dim, dim),\n",
    "            nn.BatchNorm1d(dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return x + self.layer(x) # Skip connection\n",
    "\n",
    "class ResMLP(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes):\n",
    "        super(ResMLP, self).__init__()\n",
    "        self.entry = nn.Sequential(\n",
    "            nn.Linear(input_dim, 1024),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "        self.blocks = nn.Sequential(\n",
    "            ResidualBlock(1024),\n",
    "            ResidualBlock(1024)\n",
    "        )\n",
    "        self.head = nn.Linear(1024, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.entry(x)\n",
    "        x = self.blocks(x)\n",
    "        return self.head(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T05:06:22.444125Z",
     "iopub.status.busy": "2025-12-14T05:06:22.443686Z",
     "iopub.status.idle": "2025-12-14T05:46:27.259760Z",
     "shell.execute_reply": "2025-12-14T05:46:27.259012Z",
     "shell.execute_reply.started": "2025-12-14T05:06:22.444098Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2. Bắt đầu huấn luyện...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20 | Train Loss: 0.0168 | Val Loss: 0.0149\n",
      "Epoch 2/20 | Train Loss: 0.0148 | Val Loss: 0.0144\n",
      "Epoch 3/20 | Train Loss: 0.0141 | Val Loss: 0.0141\n",
      "Epoch 4/20 | Train Loss: 0.0135 | Val Loss: 0.0139\n",
      "Epoch 5/20 | Train Loss: 0.0129 | Val Loss: 0.0139\n",
      "Epoch 6/20 | Train Loss: 0.0125 | Val Loss: 0.0139\n",
      "Epoch 7/20 | Train Loss: 0.0121 | Val Loss: 0.0140\n",
      "Epoch 8/20 | Train Loss: 0.0118 | Val Loss: 0.0140\n",
      "Epoch 9/20 | Train Loss: 0.0115 | Val Loss: 0.0142\n",
      "Epoch 10/20 | Train Loss: 0.0107 | Val Loss: 0.0140\n",
      "Epoch 11/20 | Train Loss: 0.0104 | Val Loss: 0.0141\n",
      "Epoch 12/20 | Train Loss: 0.0102 | Val Loss: 0.0142\n",
      "Epoch 13/20 | Train Loss: 0.0101 | Val Loss: 0.0141\n",
      "Epoch 14/20 | Train Loss: 0.0097 | Val Loss: 0.0144\n",
      "Epoch 15/20 | Train Loss: 0.0096 | Val Loss: 0.0143\n",
      "Epoch 16/20 | Train Loss: 0.0095 | Val Loss: 0.0143\n",
      "Epoch 17/20 | Train Loss: 0.0094 | Val Loss: 0.0145\n",
      "Epoch 18/20 | Train Loss: 0.0092 | Val Loss: 0.0145\n",
      "Epoch 19/20 | Train Loss: 0.0091 | Val Loss: 0.0143\n",
      "Epoch 20/20 | Train Loss: 0.0091 | Val Loss: 0.0146\n",
      "Huấn luyện hoàn tất. Đã lưu 'best_model.pth'.\n"
     ]
    }
   ],
   "source": [
    "# --- 4. TRAINING LOOP ---\n",
    "\n",
    "print(\"2. Bắt đầu huấn luyện...\")\n",
    "# Input dim = 400 (Di-peptide)\n",
    "model = ResMLP(input_dim=400, num_classes=NUM_LABELS).to(device)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "# Dùng AdamW + Weight Decay để chống Overfitting\n",
    "optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=1e-4)\n",
    "# Tự động giảm tốc độ học nếu không tiến bộ\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3, verbose=True)\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for features, labels in train_loader:\n",
    "        features, labels = features.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(features)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for features, labels in val_loader:\n",
    "            features, labels = features.to(device), labels.to(device)\n",
    "            outputs = model(features)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "    \n",
    "    avg_train_loss = running_loss / len(train_loader)\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    \n",
    "    scheduler.step(avg_val_loss)\n",
    "    \n",
    "    # Lưu model tốt nhất\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        torch.save(model.state_dict(), 'best_model.pth')\n",
    "            \n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS} | Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "print(\"Huấn luyện hoàn tất. Đã lưu 'best_model.pth'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T05:46:27.261068Z",
     "iopub.status.busy": "2025-12-14T05:46:27.260693Z",
     "iopub.status.idle": "2025-12-14T05:54:56.692198Z",
     "shell.execute_reply": "2025-12-14T05:54:56.691525Z",
     "shell.execute_reply.started": "2025-12-14T05:46:27.261049Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3. Đang đọc file Test và dự đoán...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_47/659956551.py:18: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:254.)\n",
      "  features_tensor = torch.tensor([features], dtype=torch.float32).to(device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đã dự đoán 2000 protein...\n",
      "Đã dự đoán 4000 protein...\n",
      "Đã dự đoán 6000 protein...\n",
      "Đã dự đoán 8000 protein...\n",
      "Đã dự đoán 10000 protein...\n",
      "Đã dự đoán 12000 protein...\n",
      "Đã dự đoán 14000 protein...\n",
      "Đã dự đoán 16000 protein...\n",
      "Đã dự đoán 18000 protein...\n",
      "Đã dự đoán 20000 protein...\n",
      "Đã dự đoán 22000 protein...\n",
      "Đã dự đoán 24000 protein...\n",
      "Đã dự đoán 26000 protein...\n",
      "Đã dự đoán 28000 protein...\n",
      "Đã dự đoán 30000 protein...\n",
      "Đã dự đoán 32000 protein...\n",
      "Đã dự đoán 34000 protein...\n",
      "Đã dự đoán 36000 protein...\n",
      "Đã dự đoán 38000 protein...\n",
      "Đã dự đoán 40000 protein...\n",
      "Đã dự đoán 42000 protein...\n",
      "Đã dự đoán 44000 protein...\n",
      "Đã dự đoán 46000 protein...\n",
      "Đã dự đoán 48000 protein...\n",
      "Đã dự đoán 50000 protein...\n",
      "Đã dự đoán 52000 protein...\n",
      "Đã dự đoán 54000 protein...\n",
      "Đã dự đoán 56000 protein...\n",
      "Đã dự đoán 58000 protein...\n",
      "Đã dự đoán 60000 protein...\n",
      "Đã dự đoán 62000 protein...\n",
      "Đã dự đoán 64000 protein...\n",
      "Đã dự đoán 66000 protein...\n",
      "Đã dự đoán 68000 protein...\n",
      "Đã dự đoán 70000 protein...\n",
      "Đã dự đoán 72000 protein...\n",
      "Đã dự đoán 74000 protein...\n",
      "Đã dự đoán 76000 protein...\n",
      "Đã dự đoán 78000 protein...\n",
      "Đã dự đoán 80000 protein...\n",
      "Đã dự đoán 82000 protein...\n",
      "Đã dự đoán 84000 protein...\n",
      "Đã dự đoán 86000 protein...\n",
      "Đã dự đoán 88000 protein...\n",
      "Đã dự đoán 90000 protein...\n",
      "Đã dự đoán 92000 protein...\n",
      "Đã dự đoán 94000 protein...\n",
      "Đã dự đoán 96000 protein...\n",
      "Đã dự đoán 98000 protein...\n",
      "Đã dự đoán 100000 protein...\n",
      "Đã dự đoán 102000 protein...\n",
      "Đã dự đoán 104000 protein...\n",
      "Đã dự đoán 106000 protein...\n",
      "Đã dự đoán 108000 protein...\n",
      "Đã dự đoán 110000 protein...\n",
      "Đã dự đoán 112000 protein...\n",
      "Đã dự đoán 114000 protein...\n",
      "Đã dự đoán 116000 protein...\n",
      "Đã dự đoán 118000 protein...\n",
      "Đã dự đoán 120000 protein...\n",
      "Đã dự đoán 122000 protein...\n",
      "Đã dự đoán 124000 protein...\n",
      "Đã dự đoán 126000 protein...\n",
      "Đã dự đoán 128000 protein...\n",
      "Đã dự đoán 130000 protein...\n",
      "Đã dự đoán 132000 protein...\n",
      "Đã dự đoán 134000 protein...\n",
      "Đã dự đoán 136000 protein...\n",
      "Đã dự đoán 138000 protein...\n",
      "Đã dự đoán 140000 protein...\n",
      "Đã dự đoán 142000 protein...\n",
      "Đã dự đoán 144000 protein...\n",
      "Đã dự đoán 146000 protein...\n",
      "Đã dự đoán 148000 protein...\n",
      "Đã dự đoán 150000 protein...\n",
      "Đã dự đoán 152000 protein...\n",
      "Đã dự đoán 154000 protein...\n",
      "Đã dự đoán 156000 protein...\n",
      "Đã dự đoán 158000 protein...\n",
      "Đã dự đoán 160000 protein...\n",
      "Đã dự đoán 162000 protein...\n",
      "Đã dự đoán 164000 protein...\n",
      "Đã dự đoán 166000 protein...\n",
      "Đã dự đoán 168000 protein...\n",
      "Đã dự đoán 170000 protein...\n",
      "Đã dự đoán 172000 protein...\n",
      "Đã dự đoán 174000 protein...\n",
      "Đã dự đoán 176000 protein...\n",
      "Đã dự đoán 178000 protein...\n",
      "Đã dự đoán 180000 protein...\n",
      "Đã dự đoán 182000 protein...\n",
      "Đã dự đoán 184000 protein...\n",
      "Đã dự đoán 186000 protein...\n",
      "Đã dự đoán 188000 protein...\n",
      "Đã dự đoán 190000 protein...\n",
      "Đã dự đoán 192000 protein...\n",
      "Đã dự đoán 194000 protein...\n",
      "Đã dự đoán 196000 protein...\n",
      "Đã dự đoán 198000 protein...\n",
      "Đã dự đoán 200000 protein...\n",
      "Đã dự đoán 202000 protein...\n",
      "Đã dự đoán 204000 protein...\n",
      "Đã dự đoán 206000 protein...\n",
      "Đã dự đoán 208000 protein...\n",
      "Đã dự đoán 210000 protein...\n",
      "Đã dự đoán 212000 protein...\n",
      "Đã dự đoán 214000 protein...\n",
      "Đã dự đoán 216000 protein...\n",
      "Đã dự đoán 218000 protein...\n",
      "Đã dự đoán 220000 protein...\n",
      "Đã dự đoán 222000 protein...\n",
      "Đã dự đoán 224000 protein...\n",
      "Dự đoán xong. File tạm: submission_temp.tsv\n"
     ]
    }
   ],
   "source": [
    "# --- 5. TẠO FILE SUBMISSION ---\n",
    "print(\"3. Đang đọc file Test và dự đoán...\")\n",
    "\n",
    "# Load lại model tốt nhất\n",
    "model.load_state_dict(torch.load('best_model.pth'))\n",
    "model.eval()\n",
    "\n",
    "test_seqs = load_fasta(TEST_SEQ_PATH)\n",
    "TEMP_SUBMISSION_FILE = 'submission_temp.tsv'\n",
    "\n",
    "with open(TEMP_SUBMISSION_FILE, 'w') as f:\n",
    "    count = 0\n",
    "    # Xử lý từng protein trong tập test\n",
    "    for pid, seq in test_seqs.items():\n",
    "        if len(seq) < 2: continue # Bỏ qua chuỗi quá ngắn\n",
    "        \n",
    "        features = get_dipeptide_composition(seq)\n",
    "        features_tensor = torch.tensor([features], dtype=torch.float32).to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            logits = model(features_tensor)\n",
    "            probs = torch.sigmoid(logits).cpu().numpy()[0]\n",
    "        \n",
    "        # Lấy các term có điểm > 0.005 (Ngưỡng thấp để giữ lại nhiều ứng viên cho bước sau)\n",
    "        # Chỉ lấy top 50 dự đoán cao nhất cho mỗi protein để giảm dung lượng\n",
    "        top_indices = np.argsort(probs)[::-1][:50]\n",
    "        \n",
    "        for idx in top_indices:\n",
    "            score = probs[idx]\n",
    "            if score > 0.005: \n",
    "                term_id = idx_to_term[idx] # Chuyển từ index số về GO ID (GO:000...)\n",
    "                f.write(f\"{pid}\\t{term_id}\\t{score:.3f}\\n\")\n",
    "        \n",
    "        count += 1\n",
    "        if count % 2000 == 0:\n",
    "            print(f\"Đã dự đoán {count} protein...\")\n",
    "\n",
    "print(f\"Dự đoán xong. File tạm: {TEMP_SUBMISSION_FILE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T05:54:56.693302Z",
     "iopub.status.busy": "2025-12-14T05:54:56.693007Z",
     "iopub.status.idle": "2025-12-14T05:55:30.226556Z",
     "shell.execute_reply": "2025-12-14T05:55:30.225751Z",
     "shell.execute_reply.started": "2025-12-14T05:54:56.693272Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting goatools\n",
      "  Downloading goatools-1.5.2-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting docopt-ng (from goatools)\n",
      "  Downloading docopt_ng-0.9.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting ftpretty (from goatools)\n",
      "  Downloading ftpretty-0.4.0-py2.py3-none-any.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from goatools) (1.26.4)\n",
      "Requirement already satisfied: openpyxl in /usr/local/lib/python3.11/dist-packages (from goatools) (3.1.5)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from goatools) (2.2.3)\n",
      "Requirement already satisfied: pydot in /usr/local/lib/python3.11/dist-packages (from goatools) (3.0.4)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from goatools) (2.32.5)\n",
      "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from goatools) (14.2.0)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from goatools) (1.15.3)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from goatools) (75.2.0)\n",
      "Requirement already satisfied: statsmodels in /usr/local/lib/python3.11/dist-packages (from goatools) (0.14.5)\n",
      "Collecting xlsxwriter (from goatools)\n",
      "  Downloading xlsxwriter-3.2.9-py3-none-any.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.11/dist-packages (from ftpretty->goatools) (2.9.0.post0)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->goatools) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->goatools) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->goatools) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->goatools) (2025.3.0)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->goatools) (2022.3.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->goatools) (2.4.1)\n",
      "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.11/dist-packages (from openpyxl->goatools) (2.0.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->goatools) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->goatools) (2025.2)\n",
      "Requirement already satisfied: pyparsing>=3.0.9 in /usr/local/lib/python3.11/dist-packages (from pydot->goatools) (3.0.9)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->goatools) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->goatools) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->goatools) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->goatools) (2025.10.5)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->goatools) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->goatools) (2.19.2)\n",
      "Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.11/dist-packages (from statsmodels->goatools) (1.0.1)\n",
      "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.11/dist-packages (from statsmodels->goatools) (25.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->goatools) (0.1.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil->ftpretty->goatools) (1.17.0)\n",
      "Requirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->goatools) (2025.3.0)\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->goatools) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->goatools) (2022.3.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->goatools) (1.4.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->goatools) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->goatools) (2024.2.0)\n",
      "Downloading goatools-1.5.2-py3-none-any.whl (15.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.8/15.8 MB\u001b[0m \u001b[31m94.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading docopt_ng-0.9.0-py3-none-any.whl (16 kB)\n",
      "Downloading ftpretty-0.4.0-py2.py3-none-any.whl (8.2 kB)\n",
      "Downloading xlsxwriter-3.2.9-py3-none-any.whl (175 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m175.3/175.3 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: xlsxwriter, docopt-ng, ftpretty, goatools\n",
      "Successfully installed docopt-ng-0.9.0 ftpretty-0.4.0 goatools-1.5.2 xlsxwriter-3.2.9\n"
     ]
    }
   ],
   "source": [
    "!pip install goatools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T05:55:30.228070Z",
     "iopub.status.busy": "2025-12-14T05:55:30.227733Z",
     "iopub.status.idle": "2025-12-14T05:58:57.316417Z",
     "shell.execute_reply": "2025-12-14T05:58:57.315595Z",
     "shell.execute_reply.started": "2025-12-14T05:55:30.228035Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4. Bắt đầu Post-processing (Lan truyền điểm)...\n",
      "Đang load cây phả hệ GO...\n",
      "/kaggle/input/btl-ml/cafa-6-protein-function-prediction/Train/go-basic.obo: fmt(1.2) rel(2025-06-01) 43,448 Terms\n",
      "Đang xử lý logic Cha-Con cho từng protein...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 224309/224309 [02:18<00:00, 1618.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đang lưu file kết quả cuối cùng...\n",
      "XONG! File nộp bài của bạn là: submission.tsv\n"
     ]
    }
   ],
   "source": [
    "# --- 6. HẬU XỬ LÝ VỚI OBO FILE ---\n",
    "from goatools.obo_parser import GODag\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "print(\"4. Bắt đầu Post-processing (Lan truyền điểm)...\")\n",
    "FINAL_OUTPUT = 'submission.tsv'\n",
    "\n",
    "# Kiểm tra file OBO\n",
    "if not os.path.exists(OBO_PATH):\n",
    "    print(\"CẢNH BÁO: Không tìm thấy file OBO. Sẽ dùng file tạm làm kết quả cuối cùng.\")\n",
    "    os.rename(TEMP_SUBMISSION_FILE, FINAL_OUTPUT)\n",
    "else:\n",
    "    print(\"Đang load cây phả hệ GO...\")\n",
    "    godag = GODag(OBO_PATH)\n",
    "\n",
    "    def propagate_scores(df_group, godag):\n",
    "        # Lấy danh sách term và score hiện tại\n",
    "        current_scores = dict(zip(df_group['GO_Term'], df_group['Score']))\n",
    "        new_scores = current_scores.copy()\n",
    "        \n",
    "        for go_id, score in current_scores.items():\n",
    "            if go_id not in godag: continue\n",
    "            \n",
    "            term_obj = godag[go_id]\n",
    "            ancestors = term_obj.get_all_parents()\n",
    "            \n",
    "            # Cha phải có điểm ít nhất bằng điểm của Con\n",
    "            for ancestor in ancestors:\n",
    "                anc_score_old = new_scores.get(ancestor, 0.0)\n",
    "                new_scores[ancestor] = max(anc_score_old, score)\n",
    "                \n",
    "        return [[pid, term, score] for term, score in new_scores.items() if score >= 0.01]\n",
    "\n",
    "    # Đọc file tạm\n",
    "    sub_df = pd.read_csv(TEMP_SUBMISSION_FILE, sep='\\t', names=['ProteinID', 'GO_Term', 'Score'])\n",
    "    \n",
    "    final_data = []\n",
    "    \n",
    "    print(\"Đang xử lý logic Cha-Con cho từng protein...\")\n",
    "    for pid, group in tqdm(sub_df.groupby('ProteinID')):\n",
    "        refined_rows = propagate_scores(group, godag)\n",
    "        for row in refined_rows:\n",
    "            # row = [pid, term, score]\n",
    "            final_data.append(row)\n",
    "            \n",
    "    # Lưu file cuối cùng\n",
    "    print(\"Đang lưu file kết quả cuối cùng...\")\n",
    "    result_df = pd.DataFrame(final_data, columns=['ProteinID', 'GO_Term', 'Score'])\n",
    "    \n",
    "    # Format điểm số 3 số lẻ\n",
    "    result_df['Score'] = result_df['Score'].map(lambda x: '{:.3f}'.format(x))\n",
    "    \n",
    "    # Lưu tsv không header\n",
    "    result_df.to_csv(FINAL_OUTPUT, sep='\\t', index=False, header=False)\n",
    "    \n",
    "    print(f\"XONG! File nộp bài của bạn là: {FINAL_OUTPUT}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 8732904,
     "sourceId": 13726215,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31192,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
