{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":116062,"databundleVersionId":14875579,"sourceType":"competition"}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# ============================================================================\n# Section 1: IMPORT VÃ€ Cáº¤U HÃŒNH\n# ============================================================================\n\nimport numpy as np\nimport pandas as pd\nimport os\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom collections import Counter\nfrom sklearn.model_selection import train_test_split\nimport gc\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# ÄÆ°á»ng dáº«n\nTRAIN_SEQ_PATH = '/kaggle/input/cafa-6-protein-function-prediction/Train/train_sequences.fasta' \nTRAIN_TERMS_PATH = '/kaggle/input/cafa-6-protein-function-prediction/Train/train_terms.tsv'\nTEST_SEQ_PATH = '/kaggle/input/cafa-6-protein-function-prediction/Test/testsuperset.fasta'\nOBO_PATH = '/kaggle/input/cafa-6-protein-function-prediction/Train/go-basic.obo'\n\n# Hyperparameters\nBATCH_SIZE = 64\nEPOCHS = 20\nLEARNING_RATE = 0.001\nNUM_LABELS = 1500\n\n# Ensemble config\nSEEDS = [42, 123, 456, 789]  # 4 seeds khÃ¡c nhau\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"ğŸ”§ Device: {device}\")\nprint(f\"ğŸ² Ensemble vá»›i {len(SEEDS)} seeds: {SEEDS}\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-13T16:39:37.710292Z","iopub.execute_input":"2025-12-13T16:39:37.710494Z","iopub.status.idle":"2025-12-13T16:39:46.053626Z","shell.execute_reply.started":"2025-12-13T16:39:37.710477Z","shell.execute_reply":"2025-12-13T16:39:46.052834Z"}},"outputs":[{"name":"stdout","text":"ğŸ”§ Device: cuda\nğŸ² Ensemble vá»›i 4 seeds: [42, 123, 456, 789]\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# ============================================================================\n# Section 2: HELPER FUNCTIONS - LOAD DATA\n# ============================================================================\n\ndef load_fasta(path):\n    \"\"\"Äá»c file FASTA vÃ  tráº£ vá» dict {protein_id: sequence}\"\"\"\n    sequences = {}\n    current_id = None\n    current_seq = []\n    \n    with open(path, 'r') as f:\n        for line in f:\n            line = line.strip()\n            if line.startswith('>'):\n                if current_id:\n                    sequences[current_id] = ''.join(current_seq)\n                \n                header = line[1:]\n                # Parse ID tá»« header\n                if '|' in header:\n                    parts = header.split('|')\n                    current_id = parts[1] if len(parts) > 1 else header.split()[0]\n                else:\n                    current_id = header.split()[0]\n                    \n                current_seq = []\n            else:\n                current_seq.append(line)\n                \n        if current_id:\n            sequences[current_id] = ''.join(current_seq)\n            \n    return sequences\n\ndef clean_sequence(seq):\n    \"\"\"\n    LÃ m sáº¡ch chuá»—i protein:\n    - Chá»‰ giá»¯ 20 amino acids chuáº©n\n    - Thay tháº¿ cÃ¡c kÃ½ tá»± Ä‘áº·c biá»‡t\n    \"\"\"\n    valid_aa = set('ACDEFGHIKLMNPQRSTVWY')\n    replacements = {'X': 'A', 'U': 'C', 'B': 'D', 'Z': 'E'}\n    \n    cleaned = []\n    for aa in seq.upper():\n        if aa in valid_aa:\n            cleaned.append(aa)\n        elif aa in replacements:\n            cleaned.append(replacements[aa])\n    \n    return ''.join(cleaned)\n\ndef is_valid_sequence(seq, min_len=50, max_len=5000):\n    \"\"\"Kiá»ƒm tra sequence cÃ³ há»£p lá»‡ khÃ´ng\"\"\"\n    length = len(seq)\n    if length < min_len or length > max_len:\n        return False\n    \n    valid_aa = set('ACDEFGHIKLMNPQRSTVWY')\n    valid_count = sum(1 for aa in seq if aa in valid_aa)\n    \n    # YÃªu cáº§u Ã­t nháº¥t 90% lÃ  amino acid chuáº©n\n    if valid_count / length < 0.9:\n        return False\n    \n    return True","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-13T16:39:46.055143Z","iopub.execute_input":"2025-12-13T16:39:46.055539Z","iopub.status.idle":"2025-12-13T16:39:46.064364Z","shell.execute_reply.started":"2025-12-13T16:39:46.055519Z","shell.execute_reply":"2025-12-13T16:39:46.063610Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# ============================================================================\n# Section 3: FEATURE EXTRACTION\n# ============================================================================\n\ndef get_dipeptide_composition(sequence):\n    \"\"\"\n    Táº¡o vector 400 chiá»u tá»« táº§n suáº¥t di-peptide\n    Input: protein sequence\n    Output: numpy array (400,)\n    \"\"\"\n    aa_list = 'ACDEFGHIKLMNPQRSTVWY'\n    aa_map = {aa: i for i, aa in enumerate(aa_list)}\n    \n    dipeptide_counts = np.zeros((20, 20), dtype=np.float32)\n    length = len(sequence)\n    \n    if length < 2:\n        return dipeptide_counts.flatten()\n    \n    # Äáº¿m táº§n suáº¥t tá»«ng cáº·p amino acid\n    for i in range(length - 1):\n        a1 = sequence[i]\n        a2 = sequence[i + 1]\n        if a1 in aa_map and a2 in aa_map:\n            dipeptide_counts[aa_map[a1], aa_map[a2]] += 1\n    \n    # Normalize báº±ng sá»‘ cáº·p\n    return dipeptide_counts.flatten() / (length - 1)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-13T16:39:46.065391Z","iopub.execute_input":"2025-12-13T16:39:46.065668Z","iopub.status.idle":"2025-12-13T16:39:46.096288Z","shell.execute_reply.started":"2025-12-13T16:39:46.065644Z","shell.execute_reply":"2025-12-13T16:39:46.095655Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# ============================================================================\n# Section 4: PREPROCESSING - LOAD VÃ€ CLEAN DATA\n# ============================================================================\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"ğŸ“‚ BÆ¯á»šC 1: LOAD VÃ€ CLEAN Dá»® LIá»†U\")\nprint(\"=\"*70)\n\n# Load train sequences\nprint(\"\\n1ï¸âƒ£ Äang load train sequences...\")\ntrain_seqs_raw = load_fasta(TRAIN_SEQ_PATH)\nprint(f\"   âœ“ Loaded: {len(train_seqs_raw)} sequences\")\n\n# Clean sequences\nprint(\"\\n2ï¸âƒ£ Äang clean sequences...\")\ntrain_seqs = {}\ninvalid_count = 0\n\nfor pid, seq in train_seqs_raw.items():\n    cleaned = clean_sequence(seq)\n    if is_valid_sequence(cleaned):\n        train_seqs[pid] = cleaned\n    else:\n        invalid_count += 1\n\nprint(f\"   âœ“ Valid sequences: {len(train_seqs)}\")\nprint(f\"   âœ— Invalid sequences: {invalid_count}\")\nprint(f\"   âœ“ Keep ratio: {len(train_seqs)/len(train_seqs_raw)*100:.1f}%\")\n\n# Load train labels\nprint(\"\\n3ï¸âƒ£ Äang load train labels...\")\ntrain_terms = pd.read_csv(TRAIN_TERMS_PATH, sep='\\t')\nprint(f\"   âœ“ Total annotations: {len(train_terms)}\")\nprint(f\"   âœ“ Unique GO terms: {train_terms['term'].nunique()}\")\n\n# Filter top terms\nprint(f\"\\n4ï¸âƒ£ Äang filter top {NUM_LABELS} GO terms...\")\ntop_terms = train_terms['term'].value_counts().head(NUM_LABELS).index.tolist()\nterm_to_idx = {term: i for i, term in enumerate(top_terms)}\nidx_to_term = {i: term for term, i in term_to_idx.items()}\n\ntrain_terms_filtered = train_terms[\n    (train_terms['term'].isin(top_terms)) &\n    (train_terms['EntryID'].isin(train_seqs.keys()))\n]\n\nprotein_to_labels = train_terms_filtered.groupby('EntryID')['term'].apply(list).to_dict()\n\n# Get valid protein IDs (cÃ³ cáº£ sequence vÃ  labels)\nvalid_ids = [pid for pid in train_seqs.keys() if pid in protein_to_labels]\nprint(f\"   âœ“ Proteins vá»›i labels: {len(valid_ids)}\")\n\n# Statistics\nseq_lengths = [len(train_seqs[pid]) for pid in valid_ids]\nlabel_counts = [len(protein_to_labels[pid]) for pid in valid_ids]\n\nprint(f\"\\nğŸ“Š THá»NG KÃŠ:\")\nprint(f\"   Sequence length: min={min(seq_lengths)}, max={max(seq_lengths)}, mean={np.mean(seq_lengths):.0f}\")\nprint(f\"   Labels per protein: min={min(label_counts)}, max={max(label_counts)}, mean={np.mean(label_counts):.1f}\")\n\n# Free memory\ndel train_seqs_raw, train_terms, train_terms_filtered\ngc.collect()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-13T16:39:46.097138Z","iopub.execute_input":"2025-12-13T16:39:46.097430Z","iopub.status.idle":"2025-12-13T16:39:56.609414Z","shell.execute_reply.started":"2025-12-13T16:39:46.097408Z","shell.execute_reply":"2025-12-13T16:39:56.608859Z"}},"outputs":[{"name":"stdout","text":"\n======================================================================\nğŸ“‚ BÆ¯á»šC 1: LOAD VÃ€ CLEAN Dá»® LIá»†U\n======================================================================\n\n1ï¸âƒ£ Äang load train sequences...\n   âœ“ Loaded: 82404 sequences\n\n2ï¸âƒ£ Äang clean sequences...\n   âœ“ Valid sequences: 81417\n   âœ— Invalid sequences: 987\n   âœ“ Keep ratio: 98.8%\n\n3ï¸âƒ£ Äang load train labels...\n   âœ“ Total annotations: 537027\n   âœ“ Unique GO terms: 26125\n\n4ï¸âƒ£ Äang filter top 1500 GO terms...\n   âœ“ Proteins vá»›i labels: 75371\n\nğŸ“Š THá»NG KÃŠ:\n   Sequence length: min=50, max=4998, mean=527\n   Labels per protein: min=1, max=111, mean=4.5\n","output_type":"stream"},{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"0"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"# ============================================================================\n# Section 5: FEATURE EXTRACTION CHO TOÃ€N Bá»˜ DATASET\n# ============================================================================\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"ğŸ”§ BÆ¯á»šC 2: FEATURE EXTRACTION\")\nprint(\"=\"*70)\n\nprint(\"\\nğŸ”¨ Äang extract dipeptide features cho táº¥t cáº£ proteins...\")\nall_features = {}\n\nfor i, pid in enumerate(valid_ids):\n    seq = train_seqs[pid]\n    features = get_dipeptide_composition(seq)\n    all_features[pid] = features\n    \n    if (i + 1) % 5000 == 0:\n        print(f\"   Progress: {i+1}/{len(valid_ids)} ({(i+1)/len(valid_ids)*100:.1f}%)\")\n\nprint(f\"\\nâœ“ Completed: {len(all_features)} feature vectors (400 dims each)\")\n\n# Verify\nsample_pid = valid_ids[0]\nprint(f\"\\nğŸ“‹ Sample check:\")\nprint(f\"   Protein ID: {sample_pid}\")\nprint(f\"   Sequence length: {len(train_seqs[sample_pid])}\")\nprint(f\"   Feature shape: {all_features[sample_pid].shape}\")\nprint(f\"   Feature range: [{all_features[sample_pid].min():.4f}, {all_features[sample_pid].max():.4f}]\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-13T16:39:56.610107Z","iopub.execute_input":"2025-12-13T16:39:56.610318Z","iopub.status.idle":"2025-12-13T16:41:32.401495Z","shell.execute_reply.started":"2025-12-13T16:39:56.610295Z","shell.execute_reply":"2025-12-13T16:41:32.400847Z"}},"outputs":[{"name":"stdout","text":"\n======================================================================\nğŸ”§ BÆ¯á»šC 2: FEATURE EXTRACTION\n======================================================================\n\nğŸ”¨ Äang extract dipeptide features cho táº¥t cáº£ proteins...\n   Progress: 5000/75371 (6.6%)\n   Progress: 10000/75371 (13.3%)\n   Progress: 15000/75371 (19.9%)\n   Progress: 20000/75371 (26.5%)\n   Progress: 25000/75371 (33.2%)\n   Progress: 30000/75371 (39.8%)\n   Progress: 35000/75371 (46.4%)\n   Progress: 40000/75371 (53.1%)\n   Progress: 45000/75371 (59.7%)\n   Progress: 50000/75371 (66.3%)\n   Progress: 55000/75371 (73.0%)\n   Progress: 60000/75371 (79.6%)\n   Progress: 65000/75371 (86.2%)\n   Progress: 70000/75371 (92.9%)\n   Progress: 75000/75371 (99.5%)\n\nâœ“ Completed: 75371 feature vectors (400 dims each)\n\nğŸ“‹ Sample check:\n   Protein ID: A0JNW5\n   Sequence length: 1464\n   Feature shape: (400,)\n   Feature range: [0.0000, 0.0150]\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# ============================================================================\n# Section 6: PYTORCH DATASET CLASS\n# ============================================================================\n\nclass CAFA6Dataset(Dataset):\n    \"\"\"PyTorch Dataset cho CAFA-6\"\"\"\n    def __init__(self, protein_ids, features_dict, label_dict, term_map, num_classes):\n        self.protein_ids = protein_ids\n        self.features_dict = features_dict\n        self.label_dict = label_dict\n        self.term_map = term_map\n        self.num_classes = num_classes\n    \n    def __len__(self):\n        return len(self.protein_ids)\n    \n    def __getitem__(self, idx):\n        pid = self.protein_ids[idx]\n        \n        # Features\n        features = self.features_dict[pid]\n        \n        # Labels (multi-hot encoding)\n        labels = np.zeros(self.num_classes, dtype=np.float32)\n        if pid in self.label_dict:\n            for term in self.label_dict[pid]:\n                if term in self.term_map:\n                    labels[self.term_map[term]] = 1.0\n        \n        return (\n            torch.tensor(features, dtype=torch.float32),\n            torch.tensor(labels, dtype=torch.float32)\n        )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-13T16:41:32.402291Z","iopub.execute_input":"2025-12-13T16:41:32.403055Z","iopub.status.idle":"2025-12-13T16:41:32.408416Z","shell.execute_reply.started":"2025-12-13T16:41:32.403035Z","shell.execute_reply":"2025-12-13T16:41:32.407780Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"# ============================================================================\n# Section 7: MODEL ARCHITECTURE\n# ============================================================================\n\nclass ResidualBlock(nn.Module):\n    \"\"\"Residual block vá»›i skip connection\"\"\"\n    def __init__(self, dim, dropout_rate=0.4):\n        super(ResidualBlock, self).__init__()\n        self.layer = nn.Sequential(\n            nn.Linear(dim, dim),\n            nn.BatchNorm1d(dim),\n            nn.ReLU(),\n            nn.Dropout(dropout_rate)\n        )\n    \n    def forward(self, x):\n        return x + self.layer(x)\n\nclass ResMLP(nn.Module):\n    \"\"\"Residual MLP cho multi-label classification\"\"\"\n    def __init__(self, input_dim=400, num_classes=1500):\n        super(ResMLP, self).__init__()\n        \n        self.entry = nn.Sequential(\n            nn.Linear(input_dim, 1024),\n            nn.BatchNorm1d(1024),\n            nn.ReLU(),\n            nn.Dropout(0.3)\n        )\n        \n        self.blocks = nn.Sequential(\n            ResidualBlock(1024, dropout_rate=0.4),\n            ResidualBlock(1024, dropout_rate=0.4)\n        )\n        \n        self.head = nn.Linear(1024, num_classes)\n    \n    def forward(self, x):\n        x = self.entry(x)\n        x = self.blocks(x)\n        return self.head(x)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-13T16:41:32.410507Z","iopub.execute_input":"2025-12-13T16:41:32.410744Z","iopub.status.idle":"2025-12-13T16:41:32.429510Z","shell.execute_reply.started":"2025-12-13T16:41:32.410729Z","shell.execute_reply":"2025-12-13T16:41:32.428784Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"# ============================================================================\n# Section 8: TRAINING FUNCTION\n# ============================================================================\n\ndef train_single_seed(seed, train_ids, val_ids, all_features, protein_to_labels, \n                      term_to_idx, save_path):\n    \"\"\"\n    Train model vá»›i 1 seed cá»¥ thá»ƒ\n    \n    Args:\n        seed: random seed\n        train_ids: list protein IDs cho training\n        val_ids: list protein IDs cho validation\n        all_features: dict features\n        protein_to_labels: dict labels\n        term_to_idx: dict term mapping\n        save_path: path lÆ°u model\n    \n    Returns:\n        best_val_loss: validation loss tá»‘t nháº¥t\n    \"\"\"\n    print(f\"\\n{'='*70}\")\n    print(f\"ğŸ² TRAINING SEED: {seed}\")\n    print(f\"{'='*70}\")\n    \n    # Set seed\n    torch.manual_seed(seed)\n    np.random.seed(seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed(seed)\n    \n    # Create datasets\n    train_dataset = CAFA6Dataset(\n        train_ids, all_features, protein_to_labels, term_to_idx, NUM_LABELS\n    )\n    val_dataset = CAFA6Dataset(\n        val_ids, all_features, protein_to_labels, term_to_idx, NUM_LABELS\n    )\n    \n    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n    \n    # Create model\n    model = ResMLP(input_dim=400, num_classes=NUM_LABELS).to(device)\n    criterion = nn.BCEWithLogitsLoss()\n    optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=1e-4)\n    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n        optimizer, mode='min', factor=0.5, patience=3, verbose=False\n    )\n    \n    best_val_loss = float('inf')\n    patience_counter = 0\n    \n    # Training loop\n    for epoch in range(EPOCHS):\n        # Train\n        model.train()\n        train_loss = 0.0\n        \n        for features, labels in train_loader:\n            features, labels = features.to(device), labels.to(device)\n            \n            optimizer.zero_grad()\n            outputs = model(features)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n            \n            train_loss += loss.item()\n        \n        avg_train_loss = train_loss / len(train_loader)\n        \n        # Validation\n        model.eval()\n        val_loss = 0.0\n        \n        with torch.no_grad():\n            for features, labels in val_loader:\n                features, labels = features.to(device), labels.to(device)\n                outputs = model(features)\n                loss = criterion(outputs, labels)\n                val_loss += loss.item()\n        \n        avg_val_loss = val_loss / len(val_loader)\n        \n        # Scheduler step\n        scheduler.step(avg_val_loss)\n        \n        # Save best model\n        if avg_val_loss < best_val_loss:\n            best_val_loss = avg_val_loss\n            torch.save(model.state_dict(), save_path)\n            patience_counter = 0\n        else:\n            patience_counter += 1\n        \n        # Print progress\n        if (epoch + 1) % 5 == 0 or epoch == 0:\n            print(f\"   Epoch {epoch+1:2d}/{EPOCHS} | \"\n                  f\"Train: {avg_train_loss:.4f} | \"\n                  f\"Val: {avg_val_loss:.4f} | \"\n                  f\"Best: {best_val_loss:.4f}\")\n    \n    print(f\"\\nâœ“ Seed {seed} completed. Best val loss: {best_val_loss:.4f}\")\n    print(f\"âœ“ Model saved to: {save_path}\")\n    \n    return best_val_loss","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-13T16:41:32.430305Z","iopub.execute_input":"2025-12-13T16:41:32.430539Z","iopub.status.idle":"2025-12-13T16:41:32.451063Z","shell.execute_reply.started":"2025-12-13T16:41:32.430513Z","shell.execute_reply":"2025-12-13T16:41:32.450473Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"# ============================================================================\n# Section 9: TRAIN ENSEMBLE (4 SEEDS)\n# ============================================================================\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"ğŸš€ BÆ¯á»šC 3: TRAINING ENSEMBLE (4 SEEDS)\")\nprint(\"=\"*70)\n\n# Táº¡o thÆ° má»¥c lÆ°u models\nos.makedirs('models', exist_ok=True)\n\nmodel_paths = []\nval_losses = []\n\nfor seed in SEEDS:\n    # Split data vá»›i seed nÃ y\n    train_ids, val_ids = train_test_split(\n        valid_ids, test_size=0.1, random_state=seed\n    )\n    \n    print(f\"\\nğŸ“Š Seed {seed}: Train={len(train_ids)}, Val={len(val_ids)}\")\n    \n    # Train\n    save_path = f'models/model_seed_{seed}.pth'\n    val_loss = train_single_seed(\n        seed, train_ids, val_ids, all_features, \n        protein_to_labels, term_to_idx, save_path\n    )\n    \n    model_paths.append(save_path)\n    val_losses.append(val_loss)\n    \n    # Free memory\n    torch.cuda.empty_cache()\n    gc.collect()\n\n# Summary\nprint(\"\\n\" + \"=\"*70)\nprint(\"ğŸ“ˆ ENSEMBLE TRAINING SUMMARY\")\nprint(\"=\"*70)\nfor seed, loss in zip(SEEDS, val_losses):\n    print(f\"   Seed {seed}: Val Loss = {loss:.4f}\")\nprint(f\"\\n   Mean Val Loss: {np.mean(val_losses):.4f}\")\nprint(f\"   Std Val Loss:  {np.std(val_losses):.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-13T16:41:32.451668Z","iopub.execute_input":"2025-12-13T16:41:32.451867Z","iopub.status.idle":"2025-12-13T16:48:04.305056Z","shell.execute_reply.started":"2025-12-13T16:41:32.451852Z","shell.execute_reply":"2025-12-13T16:48:04.304345Z"}},"outputs":[{"name":"stdout","text":"\n======================================================================\nğŸš€ BÆ¯á»šC 3: TRAINING ENSEMBLE (4 SEEDS)\n======================================================================\n\nğŸ“Š Seed 42: Train=67833, Val=7538\n\n======================================================================\nğŸ² TRAINING SEED: 42\n======================================================================\n   Epoch  1/20 | Train: 0.0175 | Val: 0.0151 | Best: 0.0151\n   Epoch  5/20 | Train: 0.0129 | Val: 0.0140 | Best: 0.0140\n   Epoch 10/20 | Train: 0.0109 | Val: 0.0142 | Best: 0.0140\n   Epoch 15/20 | Train: 0.0090 | Val: 0.0145 | Best: 0.0140\n   Epoch 20/20 | Train: 0.0084 | Val: 0.0147 | Best: 0.0140\n\nâœ“ Seed 42 completed. Best val loss: 0.0140\nâœ“ Model saved to: models/model_seed_42.pth\n\nğŸ“Š Seed 123: Train=67833, Val=7538\n\n======================================================================\nğŸ² TRAINING SEED: 123\n======================================================================\n   Epoch  1/20 | Train: 0.0175 | Val: 0.0151 | Best: 0.0151\n   Epoch  5/20 | Train: 0.0129 | Val: 0.0140 | Best: 0.0140\n   Epoch 10/20 | Train: 0.0109 | Val: 0.0142 | Best: 0.0140\n   Epoch 15/20 | Train: 0.0090 | Val: 0.0145 | Best: 0.0140\n   Epoch 20/20 | Train: 0.0084 | Val: 0.0147 | Best: 0.0140\n\nâœ“ Seed 123 completed. Best val loss: 0.0140\nâœ“ Model saved to: models/model_seed_123.pth\n\nğŸ“Š Seed 456: Train=67833, Val=7538\n\n======================================================================\nğŸ² TRAINING SEED: 456\n======================================================================\n   Epoch  1/20 | Train: 0.0175 | Val: 0.0149 | Best: 0.0149\n   Epoch  5/20 | Train: 0.0129 | Val: 0.0139 | Best: 0.0139\n   Epoch 10/20 | Train: 0.0109 | Val: 0.0141 | Best: 0.0139\n   Epoch 15/20 | Train: 0.0092 | Val: 0.0145 | Best: 0.0139\n   Epoch 20/20 | Train: 0.0084 | Val: 0.0150 | Best: 0.0139\n\nâœ“ Seed 456 completed. Best val loss: 0.0139\nâœ“ Model saved to: models/model_seed_456.pth\n\nğŸ“Š Seed 789: Train=67833, Val=7538\n\n======================================================================\nğŸ² TRAINING SEED: 789\n======================================================================\n   Epoch  1/20 | Train: 0.0175 | Val: 0.0147 | Best: 0.0147\n   Epoch  5/20 | Train: 0.0129 | Val: 0.0138 | Best: 0.0138\n   Epoch 10/20 | Train: 0.0109 | Val: 0.0140 | Best: 0.0137\n   Epoch 15/20 | Train: 0.0090 | Val: 0.0141 | Best: 0.0137\n   Epoch 20/20 | Train: 0.0085 | Val: 0.0145 | Best: 0.0137\n\nâœ“ Seed 789 completed. Best val loss: 0.0137\nâœ“ Model saved to: models/model_seed_789.pth\n\n======================================================================\nğŸ“ˆ ENSEMBLE TRAINING SUMMARY\n======================================================================\n   Seed 42: Val Loss = 0.0140\n   Seed 123: Val Loss = 0.0140\n   Seed 456: Val Loss = 0.0139\n   Seed 789: Val Loss = 0.0137\n\n   Mean Val Loss: 0.0139\n   Std Val Loss:  0.0001\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"# ============================================================================\n# Section 10: LOAD TEST DATA VÃ€ EXTRACT FEATURES\n# ============================================================================\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"ğŸ“‚ BÆ¯á»šC 4: LOAD VÃ€ PREPROCESS TEST DATA\")\nprint(\"=\"*70)\n\nprint(\"\\n1ï¸âƒ£ Äang load test sequences...\")\ntest_seqs_raw = load_fasta(TEST_SEQ_PATH)\nprint(f\"   âœ“ Loaded: {len(test_seqs_raw)} sequences\")\n\n# Clean test sequences\nprint(\"\\n2ï¸âƒ£ Äang clean test sequences...\")\ntest_seqs = {}\nfor pid, seq in test_seqs_raw.items():\n    cleaned = clean_sequence(seq)\n    if is_valid_sequence(cleaned, min_len=10):  # Lá»ng hÆ¡n cho test\n        test_seqs[pid] = cleaned\n\nprint(f\"   âœ“ Valid test sequences: {len(test_seqs)}\")\n\n# Extract features\nprint(\"\\n3ï¸âƒ£ Äang extract features cho test set...\")\ntest_features = {}\n\nfor i, (pid, seq) in enumerate(test_seqs.items()):\n    features = get_dipeptide_composition(seq)\n    test_features[pid] = features\n    \n    if (i + 1) % 5000 == 0:\n        print(f\"   Progress: {i+1}/{len(test_seqs)} ({(i+1)/len(test_seqs)*100:.1f}%)\")\n\nprint(f\"\\nâœ“ Test features ready: {len(test_features)} proteins\")\n\n# Free memory\ndel test_seqs_raw\ngc.collect()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-13T16:48:04.305778Z","iopub.execute_input":"2025-12-13T16:48:04.306144Z","iopub.status.idle":"2025-12-13T16:52:04.814988Z","shell.execute_reply.started":"2025-12-13T16:48:04.306124Z","shell.execute_reply":"2025-12-13T16:52:04.814412Z"}},"outputs":[{"name":"stdout","text":"\n======================================================================\nğŸ“‚ BÆ¯á»šC 4: LOAD VÃ€ PREPROCESS TEST DATA\n======================================================================\n\n1ï¸âƒ£ Äang load test sequences...\n   âœ“ Loaded: 224309 sequences\n\n2ï¸âƒ£ Äang clean test sequences...\n   âœ“ Valid test sequences: 223371\n\n3ï¸âƒ£ Äang extract features cho test set...\n   Progress: 5000/223371 (2.2%)\n   Progress: 10000/223371 (4.5%)\n   Progress: 15000/223371 (6.7%)\n   Progress: 20000/223371 (9.0%)\n   Progress: 25000/223371 (11.2%)\n   Progress: 30000/223371 (13.4%)\n   Progress: 35000/223371 (15.7%)\n   Progress: 40000/223371 (17.9%)\n   Progress: 45000/223371 (20.1%)\n   Progress: 50000/223371 (22.4%)\n   Progress: 55000/223371 (24.6%)\n   Progress: 60000/223371 (26.9%)\n   Progress: 65000/223371 (29.1%)\n   Progress: 70000/223371 (31.3%)\n   Progress: 75000/223371 (33.6%)\n   Progress: 80000/223371 (35.8%)\n   Progress: 85000/223371 (38.1%)\n   Progress: 90000/223371 (40.3%)\n   Progress: 95000/223371 (42.5%)\n   Progress: 100000/223371 (44.8%)\n   Progress: 105000/223371 (47.0%)\n   Progress: 110000/223371 (49.2%)\n   Progress: 115000/223371 (51.5%)\n   Progress: 120000/223371 (53.7%)\n   Progress: 125000/223371 (56.0%)\n   Progress: 130000/223371 (58.2%)\n   Progress: 135000/223371 (60.4%)\n   Progress: 140000/223371 (62.7%)\n   Progress: 145000/223371 (64.9%)\n   Progress: 150000/223371 (67.2%)\n   Progress: 155000/223371 (69.4%)\n   Progress: 160000/223371 (71.6%)\n   Progress: 165000/223371 (73.9%)\n   Progress: 170000/223371 (76.1%)\n   Progress: 175000/223371 (78.3%)\n   Progress: 180000/223371 (80.6%)\n   Progress: 185000/223371 (82.8%)\n   Progress: 190000/223371 (85.1%)\n   Progress: 195000/223371 (87.3%)\n   Progress: 200000/223371 (89.5%)\n   Progress: 205000/223371 (91.8%)\n   Progress: 210000/223371 (94.0%)\n   Progress: 215000/223371 (96.3%)\n   Progress: 220000/223371 (98.5%)\n\nâœ“ Test features ready: 223371 proteins\n","output_type":"stream"},{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"0"},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"# ============================================================================\n# Section 11: ENSEMBLE PREDICTION\n# ============================================================================\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"ğŸ”® BÆ¯á»šC 5: ENSEMBLE PREDICTION\")\nprint(\"=\"*70)\n\n# Load all models\nmodels = []\nprint(\"\\nğŸ“¥ Loading models...\")\nfor i, path in enumerate(model_paths):\n    model = ResMLP(input_dim=400, num_classes=NUM_LABELS).to(device)\n    model.load_state_dict(torch.load(path))\n    model.eval()\n    models.append(model)\n    print(f\"   âœ“ Model {i+1}/{len(models)} loaded from {path}\")\n\n# Predict vá»›i ensemble\nprint(\"\\nğŸ”® Äang dá»± Ä‘oÃ¡n vá»›i ensemble...\")\nTEMP_SUBMISSION_FILE = 'submission_temp.tsv'\n\nwith open(TEMP_SUBMISSION_FILE, 'w') as f:\n    for count, (pid, seq) in enumerate(test_seqs.items(), 1):\n        features = test_features[pid]\n        features_tensor = torch.tensor([features], dtype=torch.float32).to(device)\n        \n        # Ensemble: Average predictions tá»« 4 models\n        ensemble_probs = np.zeros(NUM_LABELS, dtype=np.float32)\n        \n        with torch.no_grad():\n            for model in models:\n                logits = model(features_tensor)\n                probs = torch.sigmoid(logits).cpu().numpy()[0]\n                ensemble_probs += probs\n        \n        # Average\n        ensemble_probs /= len(models)\n        \n        # Láº¥y top 50 predictions\n        top_indices = np.argsort(ensemble_probs)[::-1][:50]\n        \n        for idx in top_indices:\n            score = ensemble_probs[idx]\n            if score > 0.005:\n                term_id = idx_to_term[idx]\n                f.write(f\"{pid}\\t{term_id}\\t{score:.3f}\\n\")\n        \n        if count % 2000 == 0:\n            print(f\"   Progress: {count}/{len(test_seqs)} proteins\")\n\nprint(f\"\\nâœ“ Predictions saved to: {TEMP_SUBMISSION_FILE}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-13T16:52:04.815752Z","iopub.execute_input":"2025-12-13T16:52:04.816384Z","iopub.status.idle":"2025-12-13T17:01:01.399744Z","shell.execute_reply.started":"2025-12-13T16:52:04.816366Z","shell.execute_reply":"2025-12-13T17:01:01.399094Z"}},"outputs":[{"name":"stdout","text":"\n======================================================================\nğŸ”® BÆ¯á»šC 5: ENSEMBLE PREDICTION\n======================================================================\n\nğŸ“¥ Loading models...\n   âœ“ Model 1/1 loaded from models/model_seed_42.pth\n   âœ“ Model 2/2 loaded from models/model_seed_123.pth\n   âœ“ Model 3/3 loaded from models/model_seed_456.pth\n   âœ“ Model 4/4 loaded from models/model_seed_789.pth\n\nğŸ”® Äang dá»± Ä‘oÃ¡n vá»›i ensemble...\n   Progress: 2000/223371 proteins\n   Progress: 4000/223371 proteins\n   Progress: 6000/223371 proteins\n   Progress: 8000/223371 proteins\n   Progress: 10000/223371 proteins\n   Progress: 12000/223371 proteins\n   Progress: 14000/223371 proteins\n   Progress: 16000/223371 proteins\n   Progress: 18000/223371 proteins\n   Progress: 20000/223371 proteins\n   Progress: 22000/223371 proteins\n   Progress: 24000/223371 proteins\n   Progress: 26000/223371 proteins\n   Progress: 28000/223371 proteins\n   Progress: 30000/223371 proteins\n   Progress: 32000/223371 proteins\n   Progress: 34000/223371 proteins\n   Progress: 36000/223371 proteins\n   Progress: 38000/223371 proteins\n   Progress: 40000/223371 proteins\n   Progress: 42000/223371 proteins\n   Progress: 44000/223371 proteins\n   Progress: 46000/223371 proteins\n   Progress: 48000/223371 proteins\n   Progress: 50000/223371 proteins\n   Progress: 52000/223371 proteins\n   Progress: 54000/223371 proteins\n   Progress: 56000/223371 proteins\n   Progress: 58000/223371 proteins\n   Progress: 60000/223371 proteins\n   Progress: 62000/223371 proteins\n   Progress: 64000/223371 proteins\n   Progress: 66000/223371 proteins\n   Progress: 68000/223371 proteins\n   Progress: 70000/223371 proteins\n   Progress: 72000/223371 proteins\n   Progress: 74000/223371 proteins\n   Progress: 76000/223371 proteins\n   Progress: 78000/223371 proteins\n   Progress: 80000/223371 proteins\n   Progress: 82000/223371 proteins\n   Progress: 84000/223371 proteins\n   Progress: 86000/223371 proteins\n   Progress: 88000/223371 proteins\n   Progress: 90000/223371 proteins\n   Progress: 92000/223371 proteins\n   Progress: 94000/223371 proteins\n   Progress: 96000/223371 proteins\n   Progress: 98000/223371 proteins\n   Progress: 100000/223371 proteins\n   Progress: 102000/223371 proteins\n   Progress: 104000/223371 proteins\n   Progress: 106000/223371 proteins\n   Progress: 108000/223371 proteins\n   Progress: 110000/223371 proteins\n   Progress: 112000/223371 proteins\n   Progress: 114000/223371 proteins\n   Progress: 116000/223371 proteins\n   Progress: 118000/223371 proteins\n   Progress: 120000/223371 proteins\n   Progress: 122000/223371 proteins\n   Progress: 124000/223371 proteins\n   Progress: 126000/223371 proteins\n   Progress: 128000/223371 proteins\n   Progress: 130000/223371 proteins\n   Progress: 132000/223371 proteins\n   Progress: 134000/223371 proteins\n   Progress: 136000/223371 proteins\n   Progress: 138000/223371 proteins\n   Progress: 140000/223371 proteins\n   Progress: 142000/223371 proteins\n   Progress: 144000/223371 proteins\n   Progress: 146000/223371 proteins\n   Progress: 148000/223371 proteins\n   Progress: 150000/223371 proteins\n   Progress: 152000/223371 proteins\n   Progress: 154000/223371 proteins\n   Progress: 156000/223371 proteins\n   Progress: 158000/223371 proteins\n   Progress: 160000/223371 proteins\n   Progress: 162000/223371 proteins\n   Progress: 164000/223371 proteins\n   Progress: 166000/223371 proteins\n   Progress: 168000/223371 proteins\n   Progress: 170000/223371 proteins\n   Progress: 172000/223371 proteins\n   Progress: 174000/223371 proteins\n   Progress: 176000/223371 proteins\n   Progress: 178000/223371 proteins\n   Progress: 180000/223371 proteins\n   Progress: 182000/223371 proteins\n   Progress: 184000/223371 proteins\n   Progress: 186000/223371 proteins\n   Progress: 188000/223371 proteins\n   Progress: 190000/223371 proteins\n   Progress: 192000/223371 proteins\n   Progress: 194000/223371 proteins\n   Progress: 196000/223371 proteins\n   Progress: 198000/223371 proteins\n   Progress: 200000/223371 proteins\n   Progress: 202000/223371 proteins\n   Progress: 204000/223371 proteins\n   Progress: 206000/223371 proteins\n   Progress: 208000/223371 proteins\n   Progress: 210000/223371 proteins\n   Progress: 212000/223371 proteins\n   Progress: 214000/223371 proteins\n   Progress: 216000/223371 proteins\n   Progress: 218000/223371 proteins\n   Progress: 220000/223371 proteins\n   Progress: 222000/223371 proteins\n\nâœ“ Predictions saved to: submission_temp.tsv\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"# ============================================================================\n# Section 12: POST-PROCESSING (GO HIERARCHY PROPAGATION)\n# ============================================================================\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"ğŸŒ³ BÆ¯á»šC 6: POST-PROCESSING (GO Hierarchy)\")\nprint(\"=\"*70)\n\nFINAL_OUTPUT = 'submission.tsv'\n\n# Install goatools náº¿u cáº§n\ntry:\n    from goatools.obo_parser import GODag\nexcept ImportError:\n    print(\"ğŸ“¦ Installing goatools...\")\n    import subprocess\n    import sys\n    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"goatools\", \"-q\"])\n    from goatools.obo_parser import GODag\n\nif not os.path.exists(OBO_PATH):\n    print(\"âš ï¸  OBO file not found. Using raw predictions.\")\n    os.rename(TEMP_SUBMISSION_FILE, FINAL_OUTPUT)\nelse:\n    print(\"\\n1ï¸âƒ£ Loading GO hierarchy...\")\n    godag = GODag(OBO_PATH)\n    print(f\"   âœ“ Loaded {len(godag)} GO terms\")\n    \n    def propagate_scores(df_group, godag):\n        \"\"\"Propagate scores lÃªn ancestor terms\"\"\"\n        current_scores = dict(zip(df_group['GO_Term'], df_group['Score']))\n        new_scores = current_scores.copy()\n        \n        for go_id, score in current_scores.items():\n            if go_id not in godag:\n                continue\n            \n            term_obj = godag[go_id]\n            ancestors = term_obj.get_all_parents()\n            \n            # Parent pháº£i cÃ³ score >= child\n            for ancestor in ancestors:\n                anc_score_old = new_scores.get(ancestor, 0.0)\n                new_scores[ancestor] = max(anc_score_old, score)\n        \n        return [[pid, term, score] for term, score in new_scores.items() if score >= 0.01]\n    \n    # Load temp submission\n    print(\"\\n2ï¸âƒ£ Loading predictions...\")\n    sub_df = pd.read_csv(TEMP_SUBMISSION_FILE, sep='\\t', \n                         names=['ProteinID', 'GO_Term', 'Score'])\n    print(f\"   âœ“ Loaded {len(sub_df)} predictions\")\n    \n    # Propagate\n    print(\"\\n3ï¸âƒ£ Propagating scores...\")\n    final_data = []\n    \n    try:\n        from tqdm import tqdm\n        iterator = tqdm(sub_df.groupby('ProteinID'), desc=\"   Proteins\")\n    except ImportError:\n        iterator = sub_df.groupby('ProteinID')\n        print(\"   (Processing without progress bar)\")\n    \n    for pid, group in iterator:\n        refined_rows = propagate_scores(group, godag)\n        final_data.extend(refined_rows)\n    \n    # Save final submission\n    print(\"\\n4ï¸âƒ£ Saving final submission...\")\n    result_df = pd.DataFrame(final_data, columns=['ProteinID', 'GO_Term', 'Score'])\n    result_df['Score'] = result_df['Score'].map(lambda x: f'{x:.3f}')\n    result_df.to_csv(FINAL_OUTPUT, sep='\\t', index=False, header=False)\n    \n    print(f\"   âœ“ Total predictions: {len(result_df)}\")\n    print(f\"   âœ“ Unique proteins: {result_df['ProteinID'].nunique()}\")\n    print(f\"   âœ“ Unique GO terms: {result_df['GO_Term'].nunique()}\")\n\nprint(\"\\n\" + \"=\"*70)\nprint(f\"âœ… HOÃ€N Táº¤T! File submission: {FINAL_OUTPUT}\")\nprint(\"=\"*70)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-13T17:01:01.400527Z","iopub.execute_input":"2025-12-13T17:01:01.400791Z","iopub.status.idle":"2025-12-13T17:04:35.803534Z","shell.execute_reply.started":"2025-12-13T17:01:01.400774Z","shell.execute_reply":"2025-12-13T17:04:35.802861Z"}},"outputs":[{"name":"stdout","text":"\n======================================================================\nğŸŒ³ BÆ¯á»šC 6: POST-PROCESSING (GO Hierarchy)\n======================================================================\nğŸ“¦ Installing goatools...\n   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 15.8/15.8 MB 71.5 MB/s eta 0:00:00\n   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 175.3/175.3 kB 8.6 MB/s eta 0:00:00\n\n1ï¸âƒ£ Loading GO hierarchy...\n/kaggle/input/cafa-6-protein-function-prediction/Train/go-basic.obo: fmt(1.2) rel(2025-06-01) 43,448 Terms\n   âœ“ Loaded 43448 GO terms\n\n2ï¸âƒ£ Loading predictions...\n   âœ“ Loaded 10266484 predictions\n\n3ï¸âƒ£ Propagating scores...\n","output_type":"stream"},{"name":"stderr","text":"   Proteins: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 223371/223371 [01:59<00:00, 1866.11it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n4ï¸âƒ£ Saving final submission...\n   âœ“ Total predictions: 28752156\n   âœ“ Unique proteins: 223369\n   âœ“ Unique GO terms: 2935\n\n======================================================================\nâœ… HOÃ€N Táº¤T! File submission: submission.tsv\n======================================================================\n","output_type":"stream"}],"execution_count":12}]}