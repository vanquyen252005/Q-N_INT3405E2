{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":116062,"databundleVersionId":14875579,"isSourceIdPinned":false,"sourceType":"competition"},{"sourceId":13665986,"sourceType":"datasetVersion","datasetId":8688768}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# ============================================================================\n\n# Section 1: C·∫§U H√åNH & IMPORT\n\n# ============================================================================\n\nimport numpy as np\n\nimport pandas as pd\n\nimport os\n\nimport torch\n\nimport torch.nn as nn\n\nimport torch.optim as optim\n\nfrom torch.utils.data import Dataset, DataLoader\n\nfrom sklearn.model_selection import train_test_split\n\nfrom sklearn.preprocessing import StandardScaler\n\nimport gc\n\nimport warnings\n\n!pip install goatools\n\nwarnings.filterwarnings('ignore')\n\nEMBED_DIR = '/kaggle/input/cafa-6-t5-embeddings' \n\nTRAIN_TERMS_PATH = '/kaggle/input/cafa-6-protein-function-prediction/Train/train_terms.tsv'\n\nOBO_PATH = '/kaggle/input/cafa-6-protein-function-prediction/Train/go-basic.obo'\n\n\n\n# --- HYPERPARAMETERS ---\n\nBATCH_SIZE = 512       \n\nEPOCHS = 25           \n\nLEARNING_RATE = 1e-3   \n\nNUM_LABELS = 1500   \n\nSEEDS = [42, 2024, 123, 777, 888] # Ensemble 5 m√¥ h√¨nh\n\n\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nprint(f\"üîß Device: {device}\")\n\nprint(\"üöÄ Strategy: T5 Embeddings Only + MLP Multi-label\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-13T16:17:14.277841Z","iopub.execute_input":"2025-12-13T16:17:14.278064Z","iopub.status.idle":"2025-12-13T16:17:52.350336Z","shell.execute_reply.started":"2025-12-13T16:17:14.278046Z","shell.execute_reply":"2025-12-13T16:17:52.349577Z"}},"outputs":[{"name":"stdout","text":"Collecting goatools\n  Downloading goatools-1.5.2-py3-none-any.whl.metadata (14 kB)\nCollecting docopt-ng (from goatools)\n  Downloading docopt_ng-0.9.0-py3-none-any.whl.metadata (13 kB)\nCollecting ftpretty (from goatools)\n  Downloading ftpretty-0.4.0-py2.py3-none-any.whl.metadata (6.6 kB)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from goatools) (1.26.4)\nRequirement already satisfied: openpyxl in /usr/local/lib/python3.11/dist-packages (from goatools) (3.1.5)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from goatools) (2.2.3)\nRequirement already satisfied: pydot in /usr/local/lib/python3.11/dist-packages (from goatools) (3.0.4)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from goatools) (2.32.5)\nRequirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from goatools) (14.2.0)\nRequirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from goatools) (1.15.3)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from goatools) (75.2.0)\nRequirement already satisfied: statsmodels in /usr/local/lib/python3.11/dist-packages (from goatools) (0.14.5)\nCollecting xlsxwriter (from goatools)\n  Downloading xlsxwriter-3.2.9-py3-none-any.whl.metadata (2.7 kB)\nRequirement already satisfied: python-dateutil in /usr/local/lib/python3.11/dist-packages (from ftpretty->goatools) (2.9.0.post0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->goatools) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->goatools) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->goatools) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->goatools) (2025.3.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->goatools) (2022.3.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->goatools) (2.4.1)\nRequirement already satisfied: et-xmlfile in /usr/local/lib/python3.11/dist-packages (from openpyxl->goatools) (2.0.0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->goatools) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->goatools) (2025.2)\nRequirement already satisfied: pyparsing>=3.0.9 in /usr/local/lib/python3.11/dist-packages (from pydot->goatools) (3.0.9)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->goatools) (3.4.4)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->goatools) (3.11)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->goatools) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->goatools) (2025.10.5)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->goatools) (4.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->goatools) (2.19.2)\nRequirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.11/dist-packages (from statsmodels->goatools) (1.0.1)\nRequirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.11/dist-packages (from statsmodels->goatools) (25.0)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->goatools) (0.1.2)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil->ftpretty->goatools) (1.17.0)\nRequirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->goatools) (2025.3.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->goatools) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->goatools) (2022.3.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->goatools) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->goatools) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->goatools) (2024.2.0)\nDownloading goatools-1.5.2-py3-none-any.whl (15.8 MB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m15.8/15.8 MB\u001b[0m \u001b[31m83.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading docopt_ng-0.9.0-py3-none-any.whl (16 kB)\nDownloading ftpretty-0.4.0-py2.py3-none-any.whl (8.2 kB)\nDownloading xlsxwriter-3.2.9-py3-none-any.whl (175 kB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m175.3/175.3 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: xlsxwriter, docopt-ng, ftpretty, goatools\nSuccessfully installed docopt-ng-0.9.0 ftpretty-0.4.0 goatools-1.5.2 xlsxwriter-3.2.9\nüîß Device: cuda\nüöÄ Strategy: T5 Embeddings Only + MLP Multi-label\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# ============================================================================\n\n# Section 2: LOAD D·ªÆ LI·ªÜU & CHU·∫®N H√ìA (STANDARD SCALER)\n\n# ============================================================================\n\nprint(\"\\n\" + \"=\"*60)\n\nprint(\"üìÇ B∆Ø·ªöC 1: LOAD D·ªÆ LI·ªÜU T5 & CHU·∫®N H√ìA\")\n\nprint(\"=\"*60)\n\n\n\n# H√†m l√†m s·∫°ch ID ƒë·ªÉ kh·ªõp gi·ªØa c√°c file\n\ndef clean_id(pid):\n\n    if isinstance(pid, bytes): pid = pid.decode('utf-8')\n\n    pid = str(pid).strip()\n\n    if '|' in pid: \n\n        parts = pid.split('|')\n\n        return parts[1] if len(parts) >= 2 else pid\n\n    return pid\n\nclean_func = np.vectorize(clean_id)\n\n\n\n# 1. Load T5 Embeddings (Train)\n\nprint(\"1Ô∏è‚É£ Loading T5 Train Embeddings...\")\n\ntry:\n\n    X_raw = np.load(os.path.join(EMBED_DIR, 'train_embeds.npy'))\n\n    ids = clean_func(np.load(os.path.join(EMBED_DIR, 'train_ids.npy'))) \n\n    print(f\"   ‚úì Loaded Shape: {X_raw.shape}\")\n\nexcept Exception as e:\n\n    print(f\"‚ùå Error loading T5: {e}\"); exit()\n\n\n\n# 2. Load Labels\n\nprint(\"2Ô∏è‚É£ Loading Labels...\")\n\ndf_terms = pd.read_csv(TRAIN_TERMS_PATH, sep='\\t')\n\nif 'EntryID' not in df_terms.columns:\n\n    df_terms = pd.read_csv(TRAIN_TERMS_PATH, sep='\\t', header=None, names=['EntryID', 'term', 'aspect'])\n\ndf_terms['EntryID'] = df_terms['EntryID'].apply(clean_id)\n\n\n\n# 3. Align Data (T√¨m ID chung)\n\nprint(\"3Ô∏è‚É£ Aligning Data...\")\n\ncommon_ids = sorted(list(set(ids) & set(df_terms['EntryID'])))\n\nprint(f\"   ‚úì S·ªë l∆∞·ª£ng protein d√πng ƒë·ªÉ train: {len(common_ids)}\")\n\n\n\nif len(common_ids) == 0: raise ValueError(\"‚ùå Kh√¥ng t√¨m th·∫•y ID chung!\")\n\n\n\n# Map ID -> Index\n\nid_map = {pid: i for i, pid in enumerate(ids)}\n\nfinal_map = {pid: i for i, pid in enumerate(common_ids)}\n\n\n\n# T·∫°o ma tr·∫≠n X, y\n\nINPUT_DIM = X_raw.shape[1]\n\nX_all = np.zeros((len(common_ids), INPUT_DIM), dtype=np.float32)\n\ny_all = np.zeros((len(common_ids), NUM_LABELS), dtype=np.float32)\n\n\n\nprint(\"   -> Building Feature Matrix X...\")\n\nfor i, pid in enumerate(common_ids):\n\n    X_all[i] = X_raw[id_map[pid]]\n\n\n\nprint(\"   -> Building Label Matrix y (Multi-label)...\")\n\ntop_terms = df_terms['term'].value_counts().head(NUM_LABELS).index.tolist()\n\nterm2idx = {t: i for i, t in enumerate(top_terms)}\nidx2term = {i: t for i, t in enumerate(top_terms)}\n\n\n\nrelevant = df_terms[df_terms['EntryID'].isin(common_ids) & df_terms['term'].isin(top_terms)]\n\nfor row in relevant.itertuples(index=False):\n\n    pid = getattr(row, 'EntryID', row[0])\n\n    term = getattr(row, 'term', row[1])\n\n    if pid in final_map and term in term2idx:\n\n        y_all[final_map[pid], term2idx[term]] = 1.0\n\n\n\n# 4. CHU·∫®N H√ìA D·ªÆ LI·ªÜU\n\nprint(\"4Ô∏è‚É£ Applying StandardScaler...\")\n\nscaler = StandardScaler()\n\nX_all = scaler.fit_transform(X_all) # ƒê∆∞a v·ªÅ Mean=0, Std=1\n\nprint(\"   ‚úì Done! D·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c chu·∫©n h√≥a.\")\n\n\n\n# D·ªçn d·∫πp RAM\n\ndel X_raw, ids, df_terms, relevant\n\ngc.collect()\n\n\n\nprint(f\"‚úÖ DATA READY: X={X_all.shape}, y={y_all.shape}\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-13T16:17:52.352580Z","iopub.execute_input":"2025-12-13T16:17:52.353168Z","iopub.status.idle":"2025-12-13T16:17:59.801299Z","shell.execute_reply.started":"2025-12-13T16:17:52.353141Z","shell.execute_reply":"2025-12-13T16:17:59.800514Z"}},"outputs":[{"name":"stdout","text":"\n============================================================\nüìÇ B∆Ø·ªöC 1: LOAD D·ªÆ LI·ªÜU T5 & CHU·∫®N H√ìA\n============================================================\n1Ô∏è‚É£ Loading T5 Train Embeddings...\n   ‚úì Loaded Shape: (82404, 1024)\n2Ô∏è‚É£ Loading Labels...\n3Ô∏è‚É£ Aligning Data...\n   ‚úì S·ªë l∆∞·ª£ng protein d√πng ƒë·ªÉ train: 82404\n   -> Building Feature Matrix X...\n   -> Building Label Matrix y (Multi-label)...\n4Ô∏è‚É£ Applying StandardScaler...\n   ‚úì Done! D·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c chu·∫©n h√≥a.\n‚úÖ DATA READY: X=(82404, 1024), y=(82404, 1500)\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# ============================================================================\n\n# Section 3: MODEL (RESIDUAL MLP) & DATASET\n\n# ============================================================================\n\n\n\nclass TensorDataset(Dataset):\n\n    def __init__(self, X, y=None):\n\n        self.X = torch.tensor(X, dtype=torch.float32)\n\n        self.y = torch.tensor(y, dtype=torch.float32) if y is not None else None\n\n    def __len__(self): return len(self.X)\n\n    def __getitem__(self, idx):\n\n        if self.y is not None: return self.X[idx], self.y[idx]\n\n        return self.X[idx]\n\n\n\nclass ResidualBlock(nn.Module):\n\n    def __init__(self, dim, dropout=0.4): \n\n        super().__init__()\n\n        self.net = nn.Sequential(\n\n            nn.Linear(dim, dim),\n\n            nn.BatchNorm1d(dim), \n\n            nn.ReLU(),\n\n            nn.Dropout(dropout)\n\n        )\n\n    def forward(self, x): return x + self.net(x)\n\n\n\nclass ResMLP(nn.Module):\n\n    def __init__(self, inp_dim, out_dim):\n\n        super().__init__()\n\n        self.entry = nn.Sequential(\n\n            nn.Linear(inp_dim, 1024),\n\n            nn.BatchNorm1d(1024),\n\n            nn.ReLU(),\n\n            nn.Dropout(0.35)\n\n        )\n\n        self.blocks = nn.Sequential(\n\n            ResidualBlock(1024),\n\n            ResidualBlock(1024)\n\n        )\n\n        self.head = nn.Linear(1024, out_dim)\n\n    \n\n    def forward(self, x):\n\n        x = self.entry(x)\n\n        x = self.blocks(x)\n\n        return self.head(x)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-13T16:17:59.802099Z","iopub.execute_input":"2025-12-13T16:17:59.802469Z","iopub.status.idle":"2025-12-13T16:17:59.810244Z","shell.execute_reply.started":"2025-12-13T16:17:59.802445Z","shell.execute_reply":"2025-12-13T16:17:59.809431Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# ============================================================================\n\n# Section 4: TRAINING FUNCTION (COSINE ANNEALING SCHEDULER)\n\n# ============================================================================\n\n\n\ndef train_single_seed(seed, X_tr, y_tr, X_va, y_va, save_path):\n\n    print(f\"\\nüé≤ Training Seed: {seed}\")\n\n    torch.manual_seed(seed)\n\n    np.random.seed(seed)\n\n    \n\n    train_loader = DataLoader(TensorDataset(X_tr, y_tr), batch_size=BATCH_SIZE, shuffle=True)\n\n    val_loader = DataLoader(TensorDataset(X_va, y_va), batch_size=BATCH_SIZE, shuffle=False)\n\n    \n\n    model = ResMLP(INPUT_DIM, NUM_LABELS).to(device)\n\n    optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=1e-4) # Weight decay ch·ªëng overfit\n\n    criterion = nn.BCEWithLogitsLoss()\n\n    \n\n    # CosineAnnealingLR: Gi√∫p model \"nh·∫£y\" ra kh·ªèi local minima v√† h·ªôi t·ª• t·ªët h∆°n\n\n    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS, eta_min=1e-5)\n\n    \n\n    best_loss = float('inf')\n\n    \n\n    for ep in range(EPOCHS):\n\n        model.train()\n\n        t_loss = 0\n\n        for fx, fy in train_loader:\n\n            fx, fy = fx.to(device), fy.to(device)\n\n            optimizer.zero_grad()\n\n            out = model(fx)\n\n            loss = criterion(out, fy)\n\n            loss.backward()\n\n            optimizer.step()\n\n            t_loss += loss.item()\n\n            \n\n        model.eval()\n\n        v_loss = 0\n\n        with torch.no_grad():\n\n            for fx, fy in val_loader:\n\n                v_loss += criterion(model(fx.to(device)), fy.to(device)).item()\n\n        \n\n        avg_v = v_loss/len(val_loader)\n\n        \n\n        if avg_v < best_loss:\n\n            best_loss = avg_v\n\n            torch.save(model.state_dict(), save_path)\n\n            \n\n        scheduler.step() # C·∫≠p nh·∫≠t learning rate\n\n        \n\n        if (ep+1) % 5 == 0:\n\n            lr_curr = optimizer.param_groups[0]['lr']\n\n            print(f\"   Ep {ep+1}/{EPOCHS}: Train={t_loss/len(train_loader):.4f} | Val={avg_v:.4f} | LR={lr_curr:.6f}\")\n\n            \n\n    return best_loss","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-13T16:17:59.810932Z","iopub.execute_input":"2025-12-13T16:17:59.811244Z","iopub.status.idle":"2025-12-13T16:17:59.826686Z","shell.execute_reply.started":"2025-12-13T16:17:59.811226Z","shell.execute_reply":"2025-12-13T16:17:59.825967Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# ============================================================================\n\n# Section 5: CH·∫†Y TRAINING (ENSEMBLE 5 SEEDS)\n\n# ============================================================================\n\nprint(\"\\n\" + \"=\"*60)\n\nprint(\"üöÄ B∆Ø·ªöC 2: TRAIN ENSEMBLE MODELS\")\n\nprint(\"=\"*60)\n\n\n\nos.makedirs('models_t5_final', exist_ok=True)\n\nmodel_paths = []\n\n\n\nfor seed in SEEDS:\n\n    X_tr, X_va, y_tr, y_va = train_test_split(X_all, y_all, test_size=0.1, random_state=seed)\n\n    path = f'models_t5_final/model_{seed}.pth'\n\n    train_single_seed(seed, X_tr, y_tr, X_va, y_va, path)\n\n    model_paths.append(path)\n\n    \n\n    del X_tr, X_va, y_tr, y_va\n\n    gc.collect()\n\n    torch.cuda.empty_cache()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-13T16:17:59.827410Z","iopub.execute_input":"2025-12-13T16:17:59.827617Z","iopub.status.idle":"2025-12-13T16:21:03.049212Z","shell.execute_reply.started":"2025-12-13T16:17:59.827593Z","shell.execute_reply":"2025-12-13T16:21:03.048643Z"}},"outputs":[{"name":"stdout","text":"\n============================================================\nüöÄ B∆Ø·ªöC 2: TRAIN ENSEMBLE MODELS\n============================================================\n\nüé≤ Training Seed: 42\n   Ep 5/25: Train=0.0112 | Val=0.0112 | LR=0.000905\n   Ep 10/25: Train=0.0102 | Val=0.0109 | LR=0.000658\n   Ep 15/25: Train=0.0095 | Val=0.0107 | LR=0.000352\n   Ep 20/25: Train=0.0090 | Val=0.0107 | LR=0.000105\n   Ep 25/25: Train=0.0088 | Val=0.0107 | LR=0.000010\n\nüé≤ Training Seed: 2024\n   Ep 5/25: Train=0.0112 | Val=0.0113 | LR=0.000905\n   Ep 10/25: Train=0.0102 | Val=0.0110 | LR=0.000658\n   Ep 15/25: Train=0.0095 | Val=0.0108 | LR=0.000352\n   Ep 20/25: Train=0.0090 | Val=0.0108 | LR=0.000105\n   Ep 25/25: Train=0.0088 | Val=0.0107 | LR=0.000010\n\nüé≤ Training Seed: 123\n   Ep 5/25: Train=0.0112 | Val=0.0110 | LR=0.000905\n   Ep 10/25: Train=0.0103 | Val=0.0107 | LR=0.000658\n   Ep 15/25: Train=0.0096 | Val=0.0105 | LR=0.000352\n   Ep 20/25: Train=0.0090 | Val=0.0104 | LR=0.000105\n   Ep 25/25: Train=0.0088 | Val=0.0104 | LR=0.000010\n\nüé≤ Training Seed: 777\n   Ep 5/25: Train=0.0112 | Val=0.0111 | LR=0.000905\n   Ep 10/25: Train=0.0102 | Val=0.0107 | LR=0.000658\n   Ep 15/25: Train=0.0095 | Val=0.0106 | LR=0.000352\n   Ep 20/25: Train=0.0090 | Val=0.0105 | LR=0.000105\n   Ep 25/25: Train=0.0088 | Val=0.0105 | LR=0.000010\n\nüé≤ Training Seed: 888\n   Ep 5/25: Train=0.0112 | Val=0.0112 | LR=0.000905\n   Ep 10/25: Train=0.0102 | Val=0.0108 | LR=0.000658\n   Ep 15/25: Train=0.0095 | Val=0.0106 | LR=0.000352\n   Ep 20/25: Train=0.0090 | Val=0.0106 | LR=0.000105\n   Ep 25/25: Train=0.0088 | Val=0.0105 | LR=0.000010\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# ============================================================================\n\n# Section 6: D·ª∞ ƒêO√ÅN & H·∫¨U X·ª¨ L√ù\n\n# ============================================================================\n\nprint(\"\\n\" + \"=\"*60)\n\nprint(\"üîÆ B∆Ø·ªöC 3: D·ª∞ ƒêO√ÅN & GO PROPAGATION\")\n\nprint(\"=\"*60)\n\n\n\n# 1. Load Test Data\n\nprint(\"Loading Test T5 Embeddings...\")\n\ntest_emb = np.load(os.path.join(EMBED_DIR, 'test_embeds.npy'))\n\ntest_ids = clean_func(np.load(os.path.join(EMBED_DIR, 'test_ids.npy')))\n\n\n\n# 2. Normalize Test Data (D√πng scaler t·ª´ t·∫≠p train)\n\nprint(\"Applying StandardScaler to Test Data...\")\n\ntest_X = scaler.transform(test_emb)\n\n\n\n# 3. Predict Ensemble\n\nprint(\"Predicting with 5 models...\")\n\nmodels = [ResMLP(INPUT_DIM, NUM_LABELS).to(device) for _ in model_paths]\n\nfor i, m in enumerate(models):\n\n    m.load_state_dict(torch.load(model_paths[i]))\n\n    m.eval()\n\n\n\nTEMP_FILE = 'submission_raw.tsv'\n\nloader = DataLoader(TensorDataset(test_X), batch_size=BATCH_SIZE*2, shuffle=False)\n\n\n\nwith open(TEMP_FILE, 'w') as f:\n\n    start_idx = 0\n\n    with torch.no_grad():\n\n        for fx in loader:\n\n            fx = fx.to(device)\n\n            bs = fx.size(0)\n\n            \n\n            # T√≠nh trung b√¨nh c·ªông x√°c su·∫•t c·ªßa 5 models\n\n            avg_prob = torch.zeros((bs, NUM_LABELS)).to(device)\n\n            for m in models:\n\n                avg_prob += torch.sigmoid(m(fx))\n\n            avg_prob /= len(models)\n\n            avg_prob = avg_prob.cpu().numpy()\n\n            \n\n            for k in range(bs):\n\n                pid = test_ids[start_idx + k]\n\n                probs = avg_prob[k]\n\n                # L·∫•y Top 60 ƒë·ªÉ d·ª± ph√≤ng cho b∆∞·ªõc propagation\n\n                top_k = np.argsort(probs)[::-1][:60]\n\n                \n\n                for idx in top_k:\n\n                    sc = probs[idx]\n\n                    if sc > 0.001: # Threshold th·∫•p ƒë·ªÉ gi·ªØ th√¥ng tin\n\n                        f.write(f\"{pid}\\t{idx2term[idx]}\\t{sc:.3f}\\n\")\n\n            start_idx += bs\n\n\n\nprint(f\"‚úÖ Raw Predictions Saved: {TEMP_FILE}\")\n\ndel test_X, models\n\ngc.collect()\n\n\n\n# 4. GO Hierarchy Propagation\n\nprint(\"Applying GO Propagation (Goatools)...\")\n\nFINAL_OUTPUT = 'submission.tsv'\n\n\n\ntry:\n\n    from goatools.obo_parser import GODag\n\n    if os.path.exists(OBO_PATH):\n\n        godag = GODag(OBO_PATH)\n\n        \n\n        def propagate(pid, df_grp):\n\n            scores = dict(zip(df_grp['Term'], df_grp['Score']))\n\n            new_scores = scores.copy()\n\n            for term, score in scores.items():\n\n                if term in godag:\n\n                    for parent in godag[term].get_all_parents():\n\n                        new_scores[parent] = max(new_scores.get(parent, 0), score)\n\n            return [[pid, t, s] for t, s in new_scores.items() if s >= 0.01]\n\n\n\n        df = pd.read_csv(TEMP_FILE, sep='\\t', names=['ProteinID', 'Term', 'Score'], dtype={'ProteinID': str})\n\n        final_rows = []\n\n        \n\n        # Iterator ƒë∆°n gi·∫£n\n\n        for pid, grp in df.groupby('ProteinID'):\n\n            final_rows.extend(propagate(pid, grp))\n\n            \n\n        res_df = pd.DataFrame(final_rows, columns=['ProteinID', 'Term', 'Score'])\n\n        res_df['Score'] = res_df['Score'].apply(lambda x: f\"{x:.3f}\")\n\n        res_df.to_csv(FINAL_OUTPUT, sep='\\t', index=False, header=False)\n\n        print(f\"‚úÖ DONE! Final Submission: {FINAL_OUTPUT}\")\n\n    else:\n\n        print(\"‚ö†Ô∏è No OBO found. Using raw submission.\")\n\n        os.rename(TEMP_FILE, FINAL_OUTPUT)\n\nexcept Exception as e:\n\n    print(f\"‚ö†Ô∏è Error in propagation: {e}. Using raw submission.\")\n\n    if os.path.exists(TEMP_FILE): os.rename(TEMP_FILE, FINAL_OUTPUT)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-13T16:21:03.050088Z","iopub.execute_input":"2025-12-13T16:21:03.050464Z","iopub.status.idle":"2025-12-13T16:25:06.212436Z","shell.execute_reply.started":"2025-12-13T16:21:03.050443Z","shell.execute_reply":"2025-12-13T16:25:06.211750Z"}},"outputs":[{"name":"stdout","text":"\n============================================================\nüîÆ B∆Ø·ªöC 3: D·ª∞ ƒêO√ÅN & GO PROPAGATION\n============================================================\nLoading Test T5 Embeddings...\nApplying StandardScaler to Test Data...\nPredicting with 5 models...\n‚úÖ Raw Predictions Saved: submission_raw.tsv\nApplying GO Propagation (Goatools)...\n/kaggle/input/cafa-6-protein-function-prediction/Train/go-basic.obo: fmt(1.2) rel(2025-06-01) 43,448 Terms\n‚úÖ DONE! Final Submission: submission.tsv\n","output_type":"stream"}],"execution_count":6}]}